{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eus-_UvigUmZ",
        "outputId": "981c0237-aa01-4a09-f90c-d97abc30d5fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.199-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.199-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.199 ultralytics-thop-2.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUNEQNXLdspQ",
        "outputId": "dcee271b-2aff-429b-af18-4f09217d0822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Проверка модель 1: /content/3.pt ---\n",
            "\n",
            "image 1/1 /content/test1.jpg: 384x640 (no detections), 290.2ms\n",
            "Speed: 16.8ms preprocess, 290.2ms inference, 19.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/results/model_1\u001b[0m\n",
            "\n",
            "--- Проверка модель 2: /content/2.pt ---\n",
            "\n",
            "image 1/1 /content/test1.jpg: 384x640 1 rust, 133.8ms\n",
            "Speed: 3.9ms preprocess, 133.8ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/results/model_2\u001b[0m\n",
            "\n",
            "--- Проверка модель 3: /content/1.pt ---\n",
            "\n",
            "image 1/1 /content/test1.jpg: 384x640 2 scratchs, 123.5ms\n",
            "Speed: 3.4ms preprocess, 123.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/results/model_3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "model_paths = [\n",
        "    \"/content/3.pt\",\n",
        "    \"/content/2.pt\",\n",
        "    \"/content/1.pt\"\n",
        "]\n",
        "\n",
        "\n",
        "image_path = \"/content/test1.jpg\"\n",
        "\n",
        "for i, path in enumerate(model_paths, start=1):\n",
        "    print(f\"\\n--- Проверка модель {i}: {path} ---\")\n",
        "    model = YOLO(path)\n",
        "    results = model.predict(\n",
        "        source=image_path,\n",
        "        conf=0.2,\n",
        "        save=True,\n",
        "        project=\"/content/results\",   # папка куда сохранять\n",
        "        name=f\"model_{i}\",            # подпапка для каждой модели\n",
        "        exist_ok=True                 # чтобы не ругался на существующие папки\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1a0d585",
        "outputId": "9a2d3768-b0da-4979-9441-952a7af065d6"
      },
      "source": [
        "!streamlit run car_damage_app/streamlit_app.py & npx localtunnel --port 8501"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.16.214.251:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://nice-guests-sit.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipecho.net/plain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBoVKQEdmoNK",
        "outputId": "aee8880c-49f7-4117-fbd0-38071025e83c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.16.214.251"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ceefae6",
        "outputId": "879c0dd7-38ae-4ac2-f729-f6aae32d81db"
      },
      "source": [
        "import os\n",
        "import streamlit as st # Import streamlit here for clarity, though it's used in the string\n",
        "\n",
        "# Content of car_damage_app/streamlit_app.py\n",
        "# Using a raw string (r\"\") can sometimes help with backslashes, but the issue seems to be\n",
        "# with the content itself causing a SyntaxError during the string definition.\n",
        "# Let's ensure the triple-quoted string is correctly formed.\n",
        "main_app_content = \"\"\"\n",
        "import streamlit as st\n",
        "\n",
        "# Set the page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"Car Damage Detection App\",\n",
        "    page_icon=\":car:\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# --- Apply custom CSS (optional) ---\n",
        "# You can add your style.css content here or read it from a file\n",
        "try:\n",
        "    with open(\"car_damage_app/style.css\") as f:\n",
        "        st.markdown(f\"<style>{f.read()}</style>\", unsafe_allow_html=True)\n",
        "except FileNotFoundError:\n",
        "    st.warning(\"style.css not found. Basic styling will be used.\")\n",
        "except Exception as e:\n",
        "    st.error(f\"Error loading CSS: {e}\")\n",
        "\n",
        "# --- Main page content ---\n",
        "st.title(\"Приложение для определения повреждений автомобиля\")\n",
        "\n",
        "st.write(\"Добро пожаловать! Используйте боковую панель для навигации по страницам.\")\n",
        "\n",
        "# Note: In a multi-page app, the content of the main file often serves as the\n",
        "# content for the root page (e.g., \"Homepage\"). The pages in the 'pages'\n",
        "# directory will appear in the sidebar automatically based on their filenames.\n",
        "# Ensure your pages files are correctly named (e.g., upload_page.py, results_page.py).\n",
        "\n",
        "# You can add a brief description or instructions here\n",
        "st.markdown(\\\"\\\"\\\"\n",
        "Начните с загрузки фотографий автомобиля на странице **Загрузка фотографий**\n",
        "и просмотра результатов на странице **Результаты проверки**.\n",
        "\\\"\\\"\\\")\n",
        "\n",
        "# Streamlit automatically creates navigation in the sidebar based on the\n",
        "# files in the 'pages' directory.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to the main app file\n",
        "main_app_path = \"car_damage_app/streamlit_app.py\"\n",
        "with open(main_app_path, \"w\") as f:\n",
        "    f.write(main_app_content)\n",
        "\n",
        "print(f\"Created main Streamlit app file: {main_app_path}\")\n",
        "\n",
        "# Create a placeholder style.css file if it doesn't exist\n",
        "style_css_path = \"car_damage_app/style.css\"\n",
        "if not os.path.exists(style_css_path):\n",
        "    with open(style_css_path, \"w\") as f:\n",
        "        f.write(\"\"\"\n",
        "/* Basic styling for demonstration */\n",
        ".stApp {\n",
        "    padding: 1rem;\n",
        "}\n",
        "\"\"\")\n",
        "    print(f\"Created placeholder style.css: {style_css_path}\")\n",
        "\n",
        "print(\"\\nТеперь вы можете запустить приложение Streamlit.\")\n",
        "print(\"Используйте следующую команду в новой ячейке:\")\n",
        "print(\"!streamlit run car_damage_app/streamlit_app.py & npx localtunnel --port 8501\")\n",
        "print(\"\\nПосле запуска появится ссылка localtunnel, по которой вы сможете открыть приложение в браузере.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created main Streamlit app file: car_damage_app/streamlit_app.py\n",
            "Created placeholder style.css: car_damage_app/style.css\n",
            "\n",
            "Теперь вы можете запустить приложение Streamlit.\n",
            "Используйте следующую команду в новой ячейке:\n",
            "!streamlit run car_damage_app/streamlit_app.py & npx localtunnel --port 8501\n",
            "\n",
            "После запуска появится ссылка localtunnel, по которой вы сможете открыть приложение в браузере.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb2970dd",
        "outputId": "9e7f54d6-9bab-4355-f4dc-0337b98b4a43"
      },
      "source": [
        "# Content of car_damage_app/pages/results_page.py\n",
        "results_page_content = \"\"\"\n",
        "import streamlit as st\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "# Set the title for the page\n",
        "st.title(\"Профиль водителя и результаты проверки\")\n",
        "\n",
        "# Check if detection results are available in session state\n",
        "if 'detection_results' in st.session_state and st.session_state['detection_results']:\n",
        "    processing_results = st.session_state['detection_results']\n",
        "\n",
        "    # Display information for each processed image\n",
        "    for i, result in enumerate(processing_results):\n",
        "        st.subheader(f\"Результаты для изображения {i+1}\")\n",
        "\n",
        "        # Display the original uploaded image\n",
        "        try:\n",
        "            image = Image.open(io.BytesIO(result['image_data']))\n",
        "            st.image(image, caption=f\"Фото автомобиля {i+1}\", use_column_width=True)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Не удалось отобразить изображение {i+1}: {e}\")\n",
        "\n",
        "        # Display car information\n",
        "        st.write(f\"**Марка автомобиля:** {result.get('car_make', 'Не указано')}\")\n",
        "        st.write(f\"**Госномер:** {result.get('license_plate', 'Не указано')}\")\n",
        "\n",
        "        # Display detected tags\n",
        "        tags = result.get('tags', [])\n",
        "        if tags:\n",
        "            st.write(\"**Обнаруженные теги:**\")\n",
        "            # Display tags as badges or similar (basic implementation)\n",
        "            tag_string = \", \".join(tags)\n",
        "            st.markdown(f\"**Теги:** {tag_string}\") # Basic tag display\n",
        "            # For a more Indrive-like style, you'd use custom CSS/HTML which is more complex in Streamlit\n",
        "\n",
        "        else:\n",
        "            st.write(\"**Обнаруженные теги:** Нет повреждений\")\n",
        "\n",
        "        # Optional: Display raw detections\n",
        "        # detections = result.get('detections', [])\n",
        "        # if detections:\n",
        "        #     st.write(f\"**Raw Detections:** {', '.join(detections)}\")\n",
        "\n",
        "        st.markdown(\"---\") # Separator between image results\n",
        "\n",
        "    # Add a placeholder for the driver profile section (basic)\n",
        "    st.subheader(\"Профиль водителя (Пример)\")\n",
        "    st.write(\"**Имя водителя:** Случайное Имя (для примера)\") # Placeholder for random name\n",
        "    st.write(f\"**Марка автомобиля:** {processing_results[0].get('car_make', 'Не указано')}\") # Use car make from the first image\n",
        "    st.write(f\"**Госномер:** {processing_results[0].get('license_plate', 'Не указано')}\") # Use license plate from the first image\n",
        "\n",
        "    # Combine all unique tags from all images for the profile\n",
        "    all_tags = set()\n",
        "    for result in processing_results:\n",
        "        all_tags.update(result.get('tags', []))\n",
        "\n",
        "    if all_tags:\n",
        "         st.write(\"**Общие теги повреждений:**\")\n",
        "         all_tags_string = \", \".join(list(all_tags))\n",
        "         st.markdown(f\"**Общие теги:** {all_tags_string}\") # Basic tag display\n",
        "    else:\n",
        "        st.write(\"**Общие теги повреждений:** Нет обнаружено\")\n",
        "\n",
        "\n",
        "else:\n",
        "    st.info(\"Пожалуйста, загрузите фотографии на главной странице.\")\n",
        "    # Optionally add a link or button to go back to the upload page\n",
        "    if st.button(\"Перейти к загрузке\"):\n",
        "         st.switch_page(\"streamlit_app.py\") # Assuming streamlit_app.py is your main entry point\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to the results_page.py file\n",
        "results_page_path = \"car_damage_app/pages/results_page.py\"\n",
        "with open(results_page_path, \"w\") as f:\n",
        "    f.write(results_page_content)\n",
        "\n",
        "print(f\"Created {results_page_path} for displaying results.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created car_damage_app/pages/results_page.py for displaying results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e97b6c07"
      },
      "source": [
        "# Task\n",
        "Создайте многостраничное приложение Streamlit для загрузки фотографий автомобилей, определения повреждений (царапины, битый, грязный) с помощью YOLO моделей и отображения результатов в профиле водителя в стиле Indrive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c38f772"
      },
      "source": [
        "## Настройка среды\n",
        "\n",
        "### Subtask:\n",
        "Установите Streamlit и другие необходимые библиотеки.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43c4f651"
      },
      "source": [
        "**Reasoning**:\n",
        "Install Streamlit and Pillow using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f97b4f00",
        "outputId": "4626e2a0-a970-45bc-8114-e52e9a993e60"
      },
      "source": [
        "!pip install streamlit Pillow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.3.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.49.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbf6695a"
      },
      "source": [
        "## Структура приложения\n",
        "\n",
        "### Subtask:\n",
        "Создайте структуру папок для многостраничного приложения Streamlit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a73b8d0"
      },
      "source": [
        "**Reasoning**:\n",
        "Create the directory structure and placeholder files for the Streamlit application as described in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61f5c2ed",
        "outputId": "cd7c2041-3eab-4397-9c5f-d513b4f4b909"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the main application folder name\n",
        "app_folder = \"car_damage_app\"\n",
        "pages_folder = os.path.join(app_folder, \"pages\")\n",
        "\n",
        "# Create the main application folder\n",
        "os.makedirs(app_folder, exist_ok=True)\n",
        "\n",
        "# Create the main Streamlit app file\n",
        "with open(os.path.join(app_folder, \"streamlit_app.py\"), \"w\") as f:\n",
        "    f.write(\"# This is the main Streamlit app file\")\n",
        "\n",
        "# Create the pages folder\n",
        "os.makedirs(pages_folder, exist_ok=True)\n",
        "\n",
        "# Create the page files inside the pages folder\n",
        "with open(os.path.join(pages_folder, \"upload_page.py\"), \"w\") as f:\n",
        "    f.write(\"# This is the upload page\")\n",
        "\n",
        "with open(os.path.join(pages_folder, \"results_page.py\"), \"w\") as f:\n",
        "    f.write(\"# This is the results page\")\n",
        "\n",
        "print(f\"Created directory structure for Streamlit app in '{app_folder}'\")\n",
        "print(f\"- {app_folder}/streamlit_app.py\")\n",
        "print(f\"- {pages_folder}/upload_page.py\")\n",
        "print(f\"- {pages_folder}/results_page.py\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory structure for Streamlit app in 'car_damage_app'\n",
            "- car_damage_app/streamlit_app.py\n",
            "- car_damage_app/pages/upload_page.py\n",
            "- car_damage_app/pages/results_page.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3da7efd"
      },
      "source": [
        "## Страница загрузки данных\n",
        "\n",
        "### Subtask:\n",
        "Создайте первую страницу Streamlit для загрузки фотографий и ввода информации о машине (марка, госномер).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "609a1a8e"
      },
      "source": [
        "**Reasoning**:\n",
        "Edit the `upload_page.py` file to create the first Streamlit page for uploading car photos and entering car information as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac5bf560",
        "outputId": "5fea647e-889d-487d-f6af-c23570d07251"
      },
      "source": [
        "import streamlit as st\n",
        "\n",
        "# Set the title for the page\n",
        "st.title(\"Загрузка фотографий автомобиля\")\n",
        "\n",
        "# Add a section for uploading car photos\n",
        "uploaded_files = st.file_uploader(\n",
        "    \"Загрузите фотографии автомобиля\",\n",
        "    type=['jpg', 'jpeg', 'png'],\n",
        "    accept_multiple_files=True\n",
        ")\n",
        "\n",
        "# Add input fields for the car's make and license plate\n",
        "car_make = st.text_input(\"Марка автомобиля\")\n",
        "license_plate = st.text_input(\"Госномер\")\n",
        "\n",
        "# Add a button to submit the information and uploaded files\n",
        "submit_button = st.button(\"Отправить\")\n",
        "\n",
        "# Inside an if statement that checks if the button is clicked\n",
        "if submit_button:\n",
        "    # Display a success message\n",
        "    st.success(\"Информация и фотографии получены!\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-14 14:13:52.596 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.676 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-09-14 14:13:52.677 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.678 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.679 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.680 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.682 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.685 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.688 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.689 Session state does not function when running a script without `streamlit run`\n",
            "2025-09-14 14:13:52.690 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.691 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.692 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.693 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.694 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.697 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.697 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.698 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.699 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.699 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.700 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.701 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-14 14:13:52.701 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "837b94ad"
      },
      "source": [
        "## Обработка данных и моделей\n",
        "\n",
        "### Subtask:\n",
        "Создайте логику для обработки загруженных изображений с помощью ваших YOLO моделей и определения тегов (битый, грязный, царапина).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "233d7359"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to create a function that processes the uploaded images using the YOLO models, identifies damages, tags the images, and returns the structured results. This involves loading the models, iterating through images and models, running predictions, interpreting results, and organizing the output. I will place this function in a new file to keep the `upload_page.py` clean, and then I will update `upload_page.py` to use this function and manage the session state and page switching.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83643b83",
        "outputId": "0a5f2f04-3266-4b4a-a6bd-fdebe2945b49"
      },
      "source": [
        "# Create a new file for image processing logic, e.g., processing.py\n",
        "# In a real Streamlit app, this would be a separate file.\n",
        "# For this interactive notebook environment, I'll define the function here.\n",
        "\n",
        "import io\n",
        "from ultralytics import YOLO\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "\n",
        "def process_car_images(uploaded_files, car_make, license_plate):\n",
        "    \"\"\"\n",
        "    Processes uploaded car images using YOLO models to detect damages and tags.\n",
        "\n",
        "    Args:\n",
        "        uploaded_files (list): A list of uploaded file objects from Streamlit.\n",
        "        car_make (str): The make of the car.\n",
        "        license_plate (str): The license plate number of the car.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains the\n",
        "              original image data, car make, license plate, and detected tags.\n",
        "    \"\"\"\n",
        "    model_paths = [\n",
        "        \"/content/3.pt\", # Example model path for damage detection\n",
        "        \"/content/2.pt\", # Example model path for rust detection\n",
        "        \"/content/1.pt\"  # Example model path for scratch detection\n",
        "    ]\n",
        "\n",
        "    # Load models\n",
        "    models = [YOLO(path) for path in model_paths]\n",
        "\n",
        "    results_data = []\n",
        "\n",
        "    for uploaded_file in uploaded_files:\n",
        "        # Read the image data\n",
        "        image_data = uploaded_file.getvalue()\n",
        "        image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "        detected_tags = set()\n",
        "        detections = []\n",
        "\n",
        "        # Process image with each model\n",
        "        for model in models:\n",
        "            # Perform prediction\n",
        "            # Use a temporary file or BytesIO for model.predict if it requires a path/file-like object\n",
        "            # For in-memory processing, convert PIL Image to numpy array if needed by model.predict\n",
        "            # Assuming model.predict can handle PIL Image directly or can be adapted\n",
        "            # Let's use the image object directly if possible, or save to BytesIO\n",
        "            img_bytes = io.BytesIO()\n",
        "            image.save(img_bytes, format=image.format)\n",
        "            img_bytes.seek(0) # Reset the stream position to the beginning\n",
        "\n",
        "            # Run prediction on the image\n",
        "            results = model.predict(\n",
        "                source=img_bytes,\n",
        "                conf=0.2,\n",
        "                save=False, # Don't save images to disk\n",
        "                verbose=False # Suppress verbose output\n",
        "            )\n",
        "\n",
        "            # Process results\n",
        "            for r in results:\n",
        "                # Assuming r is a results object with boxes and names\n",
        "                if r.boxes is not None and len(r.boxes) > 0:\n",
        "                    for box in r.boxes:\n",
        "                        class_id = int(box.cls)\n",
        "                        class_name = model.names[class_id]\n",
        "                        detections.append(class_name)\n",
        "\n",
        "        # Determine tags based on detections\n",
        "        if 'rust' in detections or 'dented' in detections or 'broken' in detections: # Add other damage classes as needed\n",
        "            detected_tags.add('битый')\n",
        "        if 'scratch' in detections:\n",
        "            detected_tags.add('царапина')\n",
        "        # Add logic for 'грязный' tag based on your models/criteria\n",
        "\n",
        "        results_data.append({\n",
        "            'image_data': image_data, # Store original image data\n",
        "            'car_make': car_make,\n",
        "            'license_plate': license_plate,\n",
        "            'tags': list(detected_tags), # Convert set to list for storage\n",
        "            'detections': detections # Optional: store raw detections\n",
        "        })\n",
        "\n",
        "    return results_data\n",
        "\n",
        "# Now, modify upload_page.py content to call this function\n",
        "\n",
        "# Content of upload_page.py (as a multi-line string for demonstration)\n",
        "upload_page_content = \"\"\"\n",
        "import streamlit as st\n",
        "import io\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO # Import YOLO here\n",
        "\n",
        "# Define the processing function within the same file or import it\n",
        "# Since we are in a notebook, I'll include the function definition here for now.\n",
        "# In a real app, this function would be in a separate file (e.g., processing.py)\n",
        "# and imported: from processing import process_car_images\n",
        "\n",
        "# --- Start of process_car_images function definition ---\n",
        "def process_car_images(uploaded_files, car_make, license_plate):\n",
        "    \\\"\\\"\\\"\n",
        "    Processes uploaded car images using YOLO models to detect damages and tags.\n",
        "\n",
        "    Args:\n",
        "        uploaded_files (list): A list of uploaded file objects from Streamlit.\n",
        "        car_make (str): The make of the car.\n",
        "        license_plate (str): The license plate number of the car.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains the\n",
        "              original image data, car make, license plate, and detected tags.\n",
        "    \\\"\\\"\\\"\n",
        "    model_paths = [\n",
        "        \"/content/3.pt\", # Example model path for damage detection\n",
        "        \"/content/2.pt\", # Example model path for rust detection\n",
        "        \"/content/1.pt\"  # Example model path for scratch detection\n",
        "    ]\n",
        "\n",
        "    # Load models\n",
        "    # Ensure models are loaded only once per session if possible for performance\n",
        "    # For simplicity here, we reload them in the function.\n",
        "    models = [YOLO(path) for path in model_paths]\n",
        "\n",
        "    results_data = []\n",
        "\n",
        "    for uploaded_file in uploaded_files:\n",
        "        # Read the image data\n",
        "        image_data = uploaded_file.getvalue()\n",
        "        image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "        detected_tags = set()\n",
        "        detections = []\n",
        "\n",
        "        # Process image with each model\n",
        "        for model in models:\n",
        "            # Perform prediction\n",
        "            img_bytes = io.BytesIO()\n",
        "            image.save(img_bytes, format=image.format)\n",
        "            img_bytes.seek(0) # Reset the stream position to the beginning\n",
        "\n",
        "            # Run prediction on the image\n",
        "            results = model.predict(\n",
        "                source=img_bytes,\n",
        "                conf=0.2,\n",
        "                save=False, # Don't save images to disk\n",
        "                verbose=False # Suppress verbose output\n",
        "            )\n",
        "\n",
        "            # Process results\n",
        "            for r in results:\n",
        "                if r.boxes is not None and len(r.boxes) > 0:\n",
        "                    for box in r.boxes:\n",
        "                        class_id = int(box.cls)\n",
        "                        class_name = model.names[class_id]\n",
        "                        detections.append(class_name)\n",
        "\n",
        "        # Determine tags based on detections\n",
        "        # Example logic: map YOLO classes to tags\n",
        "        if 'rust' in detections or 'dented' in detections: # Adjust based on your model's classes\n",
        "             detected_tags.add('битый')\n",
        "        if 'scratch' in detections: # Adjust based on your model's classes\n",
        "            detected_tags.add('царапина')\n",
        "        # Add logic for 'грязный' if you have a model for it or another criteria\n",
        "\n",
        "        results_data.append({\n",
        "            'image_data': image_data, # Store original image data\n",
        "            'car_make': car_make,\n",
        "            'license_plate': license_plate,\n",
        "            'tags': list(detected_tags), # Convert set to list for storage\n",
        "            'detections': detections # Optional: store raw detections\n",
        "        })\n",
        "\n",
        "    return results_data\n",
        "# --- End of process_car_images function definition ---\n",
        "\n",
        "\n",
        "# Set the title for the page\n",
        "st.title(\"Загрузка фотографий автомобиля\")\n",
        "\n",
        "# Add a section for uploading car photos\n",
        "uploaded_files = st.file_uploader(\n",
        "    \"Загрузите фотографии автомобиля\",\n",
        "    type=['jpg', 'jpeg', 'png'],\n",
        "    accept_multiple_files=True\n",
        ")\n",
        "\n",
        "# Add input fields for the car's make and license plate\n",
        "car_make = st.text_input(\"Марка автомобиля\")\n",
        "license_plate = st.text_input(\"Госномер\")\n",
        "\n",
        "# Add a button to submit the information and uploaded files\n",
        "submit_button = st.button(\"Отправить\")\n",
        "\n",
        "# Inside an if statement that checks if the button is clicked\n",
        "if submit_button and uploaded_files:\n",
        "    # Process the uploaded images and get the results\n",
        "    processing_results = process_car_images(uploaded_files, car_make, license_plate)\n",
        "\n",
        "    # Store the results in Streamlit's session state\n",
        "    st.session_state['detection_results'] = processing_results\n",
        "\n",
        "    # Switch to the results page\n",
        "    st.switch_page(\"pages/results_page.py\")\n",
        "elif submit_button and not uploaded_files:\n",
        "    st.warning(\"Пожалуйста, загрузите хотя бы одно изображение.\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Write the updated content to the upload_page.py file\n",
        "upload_page_path = \"car_damage_app/pages/upload_page.py\"\n",
        "with open(upload_page_path, \"w\") as f:\n",
        "    f.write(upload_page_content)\n",
        "\n",
        "print(f\"Updated {upload_page_path} with image processing logic and page switching.\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated car_damage_app/pages/upload_page.py with image processing logic and page switching.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18a948ff"
      },
      "source": [
        "## Страница результатов/профиля\n",
        "\n",
        "### Subtask:\n",
        "Создайте вторую страницу Streamlit для отображения результатов: загруженных фото с разметкой (если возможно), марки машины, госномера и определенных тегов.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ee24a7b"
      },
      "source": [
        "**Reasoning**:\n",
        "Write the code for the Streamlit results page to display the stored detection results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6c75055"
      },
      "source": [
        "# Task\n",
        "Создайте веб-интерфейс с помощью Gradio для загрузки изображений автомобилей, ввода информации о машине (марка, госномер), обработки изображений с помощью YOLO моделей для определения повреждений и отображения результатов (изображение с разметкой, теги), стилизованный под Indrive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99f10436"
      },
      "source": [
        "## Настройка среды gradio\n",
        "\n",
        "### Subtask:\n",
        "Установите Gradio и убедитесь, что все остальные необходимые библиотеки установлены.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79b2a79f"
      },
      "source": [
        "**Reasoning**:\n",
        "Install Gradio using pip as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bf4faee",
        "outputId": "20b7c6bd-dfa1-4d43-a273-ff90725a4850"
      },
      "source": [
        "!pip install gradio"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.44.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.17.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c3c9907"
      },
      "source": [
        "## Функция обработки изображений\n",
        "\n",
        "### Subtask:\n",
        "Создайте функцию на Python, которая будет принимать загруженное изображение, информацию о машине и использовать ваши YOLO модели для определения повреждений и тегов.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fbaa12f"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the Python function `process_car_images` that takes image files and car information, loads the YOLO models, iterates through the images and models to perform detection, determines tags based on detected classes, and structures the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55e71ff3"
      },
      "source": [
        "import io\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import os # Import os to get basename of model path\n",
        "\n",
        "def process_car_images(image_files, car_make, license_plate):\n",
        "    \"\"\"\n",
        "    Processes car images using YOLO models to detect damages and tags.\n",
        "\n",
        "    Args:\n",
        "        image_files (list): A list of file paths or file-like objects (e.g., from Gradio).\n",
        "        car_make (str): The make of the car.\n",
        "        license_plate (str): The license plate number of the car.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains the\n",
        "              original image (as a PIL Image), car make, license plate,\n",
        "              detected tags, and optionally the detected bounding boxes.\n",
        "    \"\"\"\n",
        "    model_paths = [\n",
        "        \"/content/3.pt\", # Example model path for damage detection\n",
        "        \"/content/2.pt\", # Example model path for rust detection\n",
        "        \"/content/1.pt\"  # Example model path for scratch detection\n",
        "    ]\n",
        "\n",
        "    # Load models once\n",
        "    models = []\n",
        "    for path in model_paths:\n",
        "        try:\n",
        "            model = YOLO(path)\n",
        "            models.append(model)\n",
        "            # print(f\"Successfully loaded model: {path}\") # Keep for debugging if needed\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {path}: {e}\") # Print model loading errors\n",
        "            # If a model fails to load, we can't use it for predictions.\n",
        "            # The list 'models' will only contain successfully loaded models.\n",
        "\n",
        "\n",
        "    results_data = []\n",
        "\n",
        "    for i, image_file in enumerate(image_files):\n",
        "        try:\n",
        "            # print(f\"Processing image {i+1}...\") # Keep for debugging if needed\n",
        "            # Load the image - handle different input types from Gradio\n",
        "            image = None\n",
        "            if isinstance(image_file, Image.Image):\n",
        "                image = image_file.convert(\"RGB\")\n",
        "                # print(f\"Processing image {i+1} from PIL Image object\") # Keep for debugging if needed\n",
        "            elif isinstance(image_file, (str, bytes)): # Handle file paths or bytes\n",
        "                 try:\n",
        "                     if isinstance(image_file, str):\n",
        "                          image = Image.open(image_file).convert(\"RGB\")\n",
        "                     elif isinstance(image_file, bytes):\n",
        "                          image = Image.open(io.BytesIO(image_file)).convert(\"RGB\")\n",
        "                     # print(f\"Loaded image {i+1} from path/bytes\") # Keep for debugging if needed\n",
        "                 except Exception as img_load_e:\n",
        "                     raise IOError(f\"Failed to load image {i+1}: {img_load_e}\") from img_load_e\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported image file type for image {i+1}: {type(image_file)}\")\n",
        "\n",
        "\n",
        "            detected_tags = set()\n",
        "            detections = []\n",
        "            all_boxes = [] # To store bounding boxes for potential visualization\n",
        "\n",
        "            if image is not None:\n",
        "                # Process image with each successfully loaded model\n",
        "                for model in models:\n",
        "                    model_path = getattr(model, 'ckpt_path', 'unknown_model') # Get model path if available\n",
        "                    try:\n",
        "                        # print(f\"Running prediction on image {i+1} with model {model_path}...\") # Keep for debugging if needed\n",
        "                        # Perform prediction\n",
        "                        results = model.predict(\n",
        "                            source=image,\n",
        "                            conf=0.2, # Confidence threshold\n",
        "                            save=False, # Don't save images to disk\n",
        "                            verbose=False # Suppress verbose output\n",
        "                        )\n",
        "                        # print(f\"Prediction successful for image {i+1} with model {os.path.basename(model_path)}.\") # Keep for debugging if needed\n",
        "\n",
        "\n",
        "                        # Process results from the current model\n",
        "                        for r in results:\n",
        "                            if r.boxes is not None and len(r.boxes) > 0:\n",
        "                                for box in r.boxes:\n",
        "                                    class_id = int(box.cls)\n",
        "                                    class_name = model.names[class_id]\n",
        "                                    detections.append(class_name)\n",
        "                                    # Store box coordinates and class name\n",
        "                                    all_boxes.append({\n",
        "                                        'xyxy': box.xyxy[0].tolist(), # Bounding box coordinates [x1, y1, x2, y2]\n",
        "                                        'class_name': class_name,\n",
        "                                        'confidence': float(box.conf)\n",
        "                                    })\n",
        "                                # print(f\"Detected {len(r.boxes)} objects for image {i+1} with model {os.path.basename(model_path)}. Detections: {detections}\") # Keep for debugging if needed\n",
        "                            # else:\n",
        "                                # print(f\"No objects detected for image {i+1} with model {os.path.basename(model_path)}.\") # Keep for debugging if needed\n",
        "\n",
        "\n",
        "                    except Exception as model_e:\n",
        "                        print(f\"Error during prediction for image {i+1} with model {os.path.basename(model_path)}: {model_e}\") # Print prediction errors\n",
        "                        # Add an error tag for the specific model that failed prediction\n",
        "                        detected_tags.add(f\"Ошибка модели {os.path.basename(model_path)}: {model_e}\")\n",
        "\n",
        "\n",
        "            # Determine tags based on detections across all models\n",
        "            # Filter out error tags before determining main damage tags\n",
        "            actual_detections = [d for d in detections if not d.startswith('Ошибка модели')]\n",
        "\n",
        "            if 'rust' in actual_detections or 'dented' in actual_detections or 'broken' in actual_detections: # Adjust based on your model's classes\n",
        "                 detected_tags.add('битый')\n",
        "            if 'scratch' in actual_detections: # Adjust based on your model's classes\n",
        "                detected_tags.add('царапина')\n",
        "            # Add logic for 'грязный' if you have a model for it or another criteria\n",
        "\n",
        "            # Ensure original image is included in the result only if processing was mostly successful\n",
        "            # (i.e., image loaded and models were available)\n",
        "            result_image = image if image is not None else None\n",
        "\n",
        "            results_data.append({\n",
        "                'original_image': result_image, # Store the PIL Image object or None if loading failed\n",
        "                'car_make': car_make,\n",
        "                'license_plate': license_plate,\n",
        "                'tags': list(detected_tags), # Convert set to list\n",
        "                'detections': actual_detections, # List of all detected class names (excluding errors)\n",
        "                'boxes': all_boxes, # List of bounding box details\n",
        "                'error': None # No general processing error if we reached this point\n",
        "            })\n",
        "            # print(f\"Finished processing image {i+1}. Tags: {detected_tags}\") # Keep for debugging if needed\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"General error processing image {i+1}: {e}\") # Print any other general processing errors\n",
        "            # Append an entry indicating processing failed for this image\n",
        "            results_data.append({\n",
        "                'original_image': None, # Indicate failure\n",
        "                'car_make': car_make,\n",
        "                'license_plate': license_plate,\n",
        "                'tags': [f'Общая ошибка обработки: {e}'], # Include general error message in tag\n",
        "                'detections': [],\n",
        "                'boxes': [],\n",
        "                'error': str(e) # Store the error message\n",
        "            })\n",
        "\n",
        "\n",
        "    # print(\"\\n--- Final results_data ---\") # Keep for debugging if needed\n",
        "    # for i, result in enumerate(results_data): # Keep for debugging if needed\n",
        "    #     print(f\"Image {i+1}:\") # Keep for debugging if needed\n",
        "    #     print(f\"  Car Make: {result.get('car_make')}\") # Keep for debugging if needed\n",
        "    #     print(f\"  License Plate: {result.get('license_plate')}\") # Keep for debugging if needed\n",
        "    #     print(f\"  Tags: {result.get('tags')}\") # Keep for debugging if needed\n",
        "    #     print(f\"  Detections: {result.get('detections')}\") # Keep for debugging if needed\n",
        "    #     print(f\"  Boxes: {len(result.get('boxes', []))} detected boxes\") # Keep for debugging if needed\n",
        "    #     if result.get('error'): # Keep for debugging if needed\n",
        "    #         print(f\"  Error: {result['error']}\") # Keep for debugging if needed\n",
        "    # print(\"--------------------------\\n\") # Keep for debugging if needed\n",
        "\n",
        "\n",
        "    return results_data"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30508c88"
      },
      "source": [
        "## Создание интерфейса gradio\n",
        "\n",
        "### Subtask:\n",
        "Используйте Gradio для создания веб-интерфейса с элементами для загрузки изображений, ввода текста (марка, госномер) и отображения результатов (изображение с разметкой, теги).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3da40541"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the Gradio interface structure to include input fields for multiple images, car make, and license plate, and output fields for displaying processed images and detected tags.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "4725e5f0",
        "outputId": "6a26afe4-2fdf-470d-8d4c-3db3590f2054"
      },
      "source": [
        "import gradio as gr\n",
        "import io\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Assume process_car_images function is defined in the previous step\n",
        "\n",
        "def process_for_gradio(image_list, car_make, license_plate):\n",
        "    \"\"\"\n",
        "    Wrapper function to process images for Gradio output.\n",
        "    Takes a list of Gradio Image components and returns a list of annotated images\n",
        "    and a formatted string of tags.\n",
        "    \"\"\"\n",
        "    if not image_list:\n",
        "        return [None] * 5, \"Пожалуйста, загрузите хотя бы одно изображение.\" # Return placeholders for outputs\n",
        "\n",
        "    # Convert Gradio Image components to PIL Images if necessary (Gradio often passes PIL Images directly)\n",
        "    # The process_car_images function expects file-like objects or paths, or PIL Images\n",
        "    # Let's assume image_list contains PIL Images passed by Gradio\n",
        "    # If Gradio passes paths or bytes, process_car_images needs to handle that.\n",
        "    # Based on typical Gradio behavior with Image component, it passes PIL.Image.Image\n",
        "\n",
        "    # Process images using the core logic\n",
        "    processing_results = process_car_images(image_list, car_make, license_plate)\n",
        "\n",
        "    output_images = []\n",
        "    output_tags = []\n",
        "\n",
        "    # Prepare output for Gradio\n",
        "    for i, result in enumerate(processing_results):\n",
        "        if result.get('original_image'):\n",
        "            # Annotate the image with bounding boxes and class names\n",
        "            annotated_image = result['original_image'].copy()\n",
        "            draw = ImageDraw.Draw(annotated_image)\n",
        "            font = None # Use default font\n",
        "\n",
        "            # Try to load a font\n",
        "            try:\n",
        "                font_size = max(10, annotated_image.width // 50) # Dynamic font size\n",
        "                font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", font_size) # Use a common font\n",
        "            except IOError:\n",
        "                try:\n",
        "                     font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\", font_size)\n",
        "                except IOError:\n",
        "                    print(\"Font file not found, using default PIL font.\")\n",
        "                    font = ImageFont.load_default()\n",
        "\n",
        "            for box_info in result.get('boxes', []):\n",
        "                xyxy = box_info['xyxy']\n",
        "                class_name = box_info['class_name']\n",
        "                confidence = box_info['confidence']\n",
        "                label = f\"{class_name}: {confidence:.2f}\"\n",
        "\n",
        "                # Draw bounding box\n",
        "                draw.rectangle(xyxy, outline=\"red\", width=2)\n",
        "\n",
        "                # Draw label background and text\n",
        "                text_width, text_height = draw.textbbox((0, 0), label, font=font)[2:]\n",
        "\n",
        "                # Adjust position to stay within image bounds\n",
        "                text_x = xyxy[0]\n",
        "                text_y = xyxy[1] - text_height - 5 # Position above the box\n",
        "\n",
        "                if text_y < 0: # If text is above top edge, put it below\n",
        "                    text_y = xyxy[1] + 5\n",
        "                    if text_y + text_height > annotated_image.height: # If still outside, adjust x\n",
        "                         text_x = xyxy[0] + (xyxy[2] - xyxy[0]) / 2 - text_width / 2\n",
        "                         text_y = xyxy[1] + 5 # Still below the box\n",
        "\n",
        "                # Ensure text_x is also within bounds\n",
        "                if text_x < 0: text_x = 0\n",
        "                if text_x + text_width > annotated_image.width: text_x = annotated_image.width - text_width\n",
        "\n",
        "\n",
        "                draw.rectangle([text_x, text_y, text_x + text_width, text_y + text_height], fill=\"red\")\n",
        "                draw.text((text_x, text_y), label, fill=\"white\", font=font)\n",
        "\n",
        "\n",
        "            output_images.append(annotated_image)\n",
        "        else:\n",
        "            output_images.append(None) # Append None if processing failed\n",
        "\n",
        "        # Format tags for display\n",
        "        tags = result.get('tags', [])\n",
        "        if tags:\n",
        "            output_tags.append(f\"Изображение {i+1}: {', '.join(tags)}\")\n",
        "        elif result.get('error'):\n",
        "             output_tags.append(f\"Изображение {i+1}: Ошибка обработки - {result['error']}\")\n",
        "        else:\n",
        "            output_tags.append(f\"Изображение {i+1}: Повреждения не обнаружены\")\n",
        "\n",
        "\n",
        "    # Combine all tag strings\n",
        "    all_tags_string = \"\\\\n\".join(output_tags)\n",
        "\n",
        "    # Gradio expects a fixed number of outputs.\n",
        "    # If we expect up to 5 images, return a list of 5 images and the tags string.\n",
        "    # Pad the output_images list with None if fewer than 5 images were uploaded.\n",
        "    while len(output_images) < 5:\n",
        "        output_images.append(None)\n",
        "\n",
        "\n",
        "    return output_images[0], output_images[1], output_images[2], output_images[3], output_images[4], all_tags_string\n",
        "\n",
        "\n",
        "\n",
        "# Define the Gradio interface\n",
        "# Use multiple Image components for output, up to a reasonable number (e.g., 5)\n",
        "interface = gr.Interface(\n",
        "    fn=process_for_gradio,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 1\", optional=True),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 2\", optional=True),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 3\", optional=True),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 4\", optional=True),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 5\", optional=True),\n",
        "        gr.Textbox(label=\"Марка автомобиля\"),\n",
        "        gr.Textbox(label=\"Госномер\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Результат обработки 1\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 2\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 3\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 4\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 5\", interactive=False),\n",
        "        gr.Textbox(label=\"Обнаруженные теги и информация\"),\n",
        "    ],\n",
        "    title=\"Приложение для определения повреждений автомобиля (Indrive Style)\",\n",
        "    description=\"Загрузите фотографии автомобиля, укажите марку и госномер для определения повреждений.\",\n",
        "    theme=\"default\" # Using default theme, custom styling would require CSS\n",
        ")\n",
        "\n",
        "# The interface can be launched using interface.launch()\n",
        "# In this notebook environment, we might just define it."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Image.__init__() got an unexpected keyword argument 'optional'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4057459634.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_for_gradio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     inputs=[\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pil\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Загрузите фото автомобиля 1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pil\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Загрузите фото автомобиля 2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pil\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Загрузите фото автомобиля 3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/component_meta.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Image.__init__() got an unexpected keyword argument 'optional'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5228f844"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because `gr.Image` does not accept the `optional` keyword argument. I need to remove the `optional=True` from the `gr.Image` inputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPP8VyHOnuqX"
      },
      "source": [
        "import gradio as gr\n",
        "import io\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Assume process_car_images function is defined in the previous step\n",
        "\n",
        "def process_for_gradio(image1, image2, image3, image4, image5, car_make, license_plate):\n",
        "    \"\"\"\n",
        "    Wrapper function to process images for Gradio output.\n",
        "    Takes up to 5 Gradio Image components and returns a list of annotated images\n",
        "    and a formatted string of tags.\n",
        "    \"\"\"\n",
        "    # Collect non-None images and ensure they are PIL Image objects if possible\n",
        "    image_list = []\n",
        "    for img in [image1, image2, image3, image4, image5]:\n",
        "        if img is not None:\n",
        "            if isinstance(img, Image.Image):\n",
        "                image_list.append(img)\n",
        "            # Add other type checks if Gradio might pass other formats (e.g., numpy arrays, file paths)\n",
        "            # For Gradio's Image component with type=\"pil\", it should ideally pass PIL Image.\n",
        "            else:\n",
        "                 print(f\"Warning: Unexpected image format received by Gradio wrapper: {type(img)}\")\n",
        "                 # Attempt to convert if it's a path or bytes, though type=\"pil\" should handle this\n",
        "                 try:\n",
        "                     if isinstance(img, str): # Assuming it might be a file path\n",
        "                          image_list.append(Image.open(img).convert(\"RGB\"))\n",
        "                     elif isinstance(img, bytes): # Assuming it might be bytes\n",
        "                          image_list.append(Image.open(io.BytesIO(img)).convert(\"RGB\"))\n",
        "                     # Add other conversions if necessary\n",
        "                     else:\n",
        "                          print(f\"Error: Cannot process image of type {type(img)}\")\n",
        "                          # Optionally add an error entry to results_data here if conversion fails\n",
        "                 except Exception as e:\n",
        "                      print(f\"Error converting image type: {e}\")\n",
        "                      # Optionally add an error entry to results_data here if conversion fails\n",
        "\n",
        "\n",
        "    if not image_list:\n",
        "        # Return placeholders for outputs if no images are uploaded\n",
        "        # Also return empty string for overall tags\n",
        "        return None, None, None, None, None, \"\", \"Пожалуйста, загрузите хотя бы одно изображение.\"\n",
        "\n",
        "    # Process images using the core logic\n",
        "    # The process_car_images function is expected to handle a list of PIL Image objects\n",
        "    try:\n",
        "        processing_results = process_car_images(image_list, car_make, license_plate)\n",
        "    except NameError:\n",
        "        # Handle case where process_car_images is not defined (e.g., running this cell alone)\n",
        "        return None, None, None, None, None, \"\", \"Ошибка: Функция обработки изображений не определена.\"\n",
        "    except Exception as e:\n",
        "         return None, None, None, None, None, \"\", f\"Общая ошибка обработки: {e}\"\n",
        "\n",
        "\n",
        "    output_images = []\n",
        "    output_individual_tags = []\n",
        "    overall_tags_set = set() # Set to store unique overall tags\n",
        "\n",
        "    # Prepare output for Gradio\n",
        "    for i, result in enumerate(processing_results):\n",
        "        # Check if processing was successful for this image\n",
        "        if result.get('original_image') and not result.get('error'):\n",
        "            # Annotate the image with bounding boxes and class names\n",
        "            annotated_image = result['original_image'].copy()\n",
        "            draw = ImageDraw.Draw(annotated_image)\n",
        "            font = None # Use default font\n",
        "\n",
        "            # Try to load a font\n",
        "            try:\n",
        "                font_size = max(10, annotated_image.width // 50) # Dynamic font size\n",
        "                # Use fonts commonly available in Colab\n",
        "                font_paths = [\"DejaVuSans-Bold.ttf\", \"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\"]\n",
        "                for font_path in font_paths:\n",
        "                    try:\n",
        "                        font = ImageFont.truetype(font_path, font_size)\n",
        "                        break # Found a font, exit loop\n",
        "                    except IOError:\n",
        "                        continue # Try next font\n",
        "\n",
        "                if font is None:\n",
        "                     print(\"Warning: Font file not found, using default PIL font.\")\n",
        "                     font = ImageFont.load_default()\n",
        "\n",
        "\n",
        "            except Exception as font_e:\n",
        "                print(f\"Error loading font: {font_e}\")\n",
        "                font = ImageFont.load_default() # Fallback to default font\n",
        "\n",
        "\n",
        "            for box_info in result.get('boxes', []):\n",
        "                xyxy = box_info['xyxy']\n",
        "                class_name = box_info['class_name']\n",
        "                confidence = box_info['confidence']\n",
        "                label = f\"{class_name}: {confidence:.2f}\"\n",
        "\n",
        "                # Draw bounding box\n",
        "                draw.rectangle(xyxy, outline=\"red\", width=2)\n",
        "\n",
        "                # Draw label background and text\n",
        "                try:\n",
        "                    text_width, text_height = draw.textbbox((0, 0), label, font=font)[2:]\n",
        "                except AttributeError: # Handle older PIL versions without textbbox\n",
        "                     text_width, text_height = draw.textsize(label, font=font)\n",
        "\n",
        "\n",
        "                # Adjust position to stay within image bounds\n",
        "                text_x = xyxy[0]\n",
        "                text_y = xyxy[1] - text_height - 5 # Position above the box\n",
        "\n",
        "                if text_y < 0: # If text is above top edge, put it below\n",
        "                    text_y = xyxy[1] + 5\n",
        "                    # If still outside, adjust x to center if possible\n",
        "                    if text_y + text_height > annotated_image.height:\n",
        "                         text_x = xyxy[0] + (xyxy[2] - xyxy[0]) / 2 - text_width / 2\n",
        "                         text_y = xyxy[1] + 5 # Still below the box\n",
        "\n",
        "                # Ensure text_x is also within bounds\n",
        "                if text_x < 0: text_x = 0\n",
        "                if text_x + text_width > annotated_image.width: text_x = annotated_image.width - text_width\n",
        "\n",
        "                try:\n",
        "                    draw.rectangle([text_x, text_y, text_x + text_width, text_y + text_height], fill=\"red\")\n",
        "                    draw.text((text_x, text_y), label, fill=\"white\", font=font)\n",
        "                except Exception as draw_e:\n",
        "                    print(f\"Error drawing on image: {draw_e}\")\n",
        "\n",
        "\n",
        "            output_images.append(annotated_image)\n",
        "\n",
        "            # Add individual image tags to the list\n",
        "            tags = result.get('tags', [])\n",
        "            if tags:\n",
        "                output_individual_tags.append(f\"Изображение {i+1}: {', '.join(tags)}\")\n",
        "                # Add tags to the overall set (excluding error tags for overall summary)\n",
        "                overall_tags_set.update([t for t in tags if not t.startswith('Ошибка')])\n",
        "            else:\n",
        "                output_individual_tags.append(f\"Изображение {i+1}: Повреждения не обнаружены\")\n",
        "\n",
        "        else:\n",
        "            # If processing failed or no image was returned, append None\n",
        "            output_images.append(None)\n",
        "            # Report error for this specific image\n",
        "            error_msg = result.get('error', 'Неизвестная ошибка')\n",
        "            output_individual_tags.append(f\"Изображение {i+1}: Ошибка обработки - {error_msg}\")\n",
        "            # Add general error tag to overall tags if applicable\n",
        "            overall_tags_set.add(\"Общая ошибка обработки\")\n",
        "\n",
        "\n",
        "    # Filter overall tags to include only \"битый\" and \"грязный\" and format for display\n",
        "    filtered_overall_tags = []\n",
        "    if 'битый' in overall_tags_set:\n",
        "        filtered_overall_tags.append('БИТЫЙ')\n",
        "    if 'грязный' in overall_tags_set:\n",
        "        filtered_overall_tags.append('ГРЯЗНЫЙ')\n",
        "    # Add other specific tags if needed, e.g., for errors\n",
        "    if 'Общая ошибка обработки' in overall_tags_set:\n",
        "         filtered_overall_tags.append('Общая ошибка обработки') # Include general error tag\n",
        "\n",
        "\n",
        "    overall_tags_string = \"Общие теги повреждений: \" + (\", \".join(filtered_overall_tags) if filtered_overall_tags else \"Нет обнаружено\")\n",
        "    individual_tags_string = \"\\\\n\".join(output_individual_tags)\n",
        "\n",
        "    # Combine overall and individual tags in the final output string\n",
        "    final_tags_output = f\"{overall_tags_string}\\\\n\\\\nРезультаты по изображениям:\\\\n{individual_tags_string}\"\n",
        "\n",
        "\n",
        "    # Gradio expects a fixed number of outputs.\n",
        "    # If we expect up to 5 images, return a list of 5 images and the tags string.\n",
        "    # Pad the output_images list with None if fewer than 5 images were processed successfully.\n",
        "    while len(output_images) < 5:\n",
        "        output_images.append(None)\n",
        "\n",
        "\n",
        "    # Return the 5 images and the combined tag string\n",
        "    return output_images[0], output_images[1], output_images[2], output_images[3], output_images[4], final_tags_output\n",
        "\n",
        "\n",
        "# Define the Gradio interface\n",
        "# Use multiple Image components for output, up to a reasonable number (e.g., 5)\n",
        "# The custom CSS is defined in the previous step and will be applied when the interface is launched.\n",
        "interface = gr.Interface(\n",
        "    fn=process_for_gradio,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 1\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 2\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 3\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 4\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 5\"),\n",
        "        gr.Textbox(label=\"Марка автомобиля\"),\n",
        "        gr.Textbox(label=\"Госномер\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Результат обработки 1\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 2\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 3\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 4\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 5\", interactive=False),\n",
        "        gr.Textbox(label=\"Обнаруженные теги и информация\"),\n",
        "    ],\n",
        "    title=\"Приложение для определения повреждений автомобиля (Indrive Style)\",\n",
        "    description=\"Загрузите фотографии автомобиля, укажите марку и госномер для определения повреждений.\",\n",
        "    css=\"\"\"\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';\n",
        "    background-color: #f0f2f5; /* Light grey background */\n",
        "    color: #333; /* Dark grey text */\n",
        "}\n",
        "h1, h2, h3, h4, h5, h6 {\n",
        "    color: #007bff; /* Indrive blue-ish color for headings */\n",
        "}\n",
        ".gradio-container {\n",
        "    box-shadow: 0 4px 8px rgba(0,0,0,0.1); /* Subtle shadow */\n",
        "    border-radius: 8px;\n",
        "    padding: 20px;\n",
        "    background-color: #ffffff; /* White background for the container */\n",
        "}\n",
        "/* Style for text inputs */\n",
        ".gr-textbox textarea {\n",
        "    border-color: #ced4da;\n",
        "    border-radius: 4px;\n",
        "    padding: 10px;\n",
        "}\n",
        "/* Style for buttons */\n",
        ".gr-button {\n",
        "    background-color: #007bff; /* Indrive blue-ish color */\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 4px;\n",
        "    padding: 10px 20px;\n",
        "    font-size: 16px;\n",
        "    cursor: pointer;\n",
        "    transition: background-color 0.3s ease;\n",
        "}\n",
        ".gr-button:hover {\n",
        "    background-color: #0056b3; /* Darker blue on hover */\n",
        "}\n",
        "/* Style for file upload area */\n",
        ".gr-upload-text {\n",
        "    color: #007bff; /* Indrive blue-ish color */\n",
        "}\n",
        "/* Style for labels */\n",
        ".gr-label {\n",
        "    font-weight: bold;\n",
        "    color: #555;\n",
        "}\n",
        "/* Style for output text */\n",
        ".gr-text output {\n",
        "    white-space: pre-wrap; /* Preserve line breaks in output */\n",
        "}\n",
        "\"\"\", # Apply custom CSS directly\n",
        "    # theme=gr.themes.Soft() # Example of applying a built-in theme\n",
        ")\n",
        "\n",
        "# The interface can be launched using interface.launch()\n",
        "# The launch command is in a separate cell."
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73359cc8"
      },
      "source": [
        "## Интеграция с моделями\n",
        "\n",
        "### Subtask:\n",
        "Подключите функцию обработки изображений к интерфейсу Gradio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eea8c77b"
      },
      "source": [
        "## Запуск приложения gradio\n",
        "\n",
        "### Subtask:\n",
        "Запустите веб-приложение Gradio, возможно, с использованием `share=True` для доступа через публичную ссылку в Colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c14792ec"
      },
      "source": [
        "**Reasoning**:\n",
        "Call the launch method on the Gradio interface object to start the web server and generate a public shareable URL.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "d6a9551c",
        "outputId": "9ce64fb4-3ff1-40c1-aac8-3e3edc614b3c"
      },
      "source": [
        "interface.launch(share=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://31d87e900c2402078c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://31d87e900c2402078c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b722d51"
      },
      "source": [
        "# Приложение для определения повреждений автомобиля (Indrive Style)\n",
        "\n",
        "Это веб-приложение, созданное с использованием Gradio и YOLO моделей, для загрузки фотографий автомобилей, определения типов повреждений (таких как \"битый\", \"царапина\", \"грязный\") и отображения результатов.\n",
        "\n",
        "## Описание\n",
        "\n",
        "Приложение позволяет пользователям загружать несколько фотографий автомобиля и предоставлять основную информацию (марка, госномер). Затем оно использует предобученные YOLO модели для анализа каждого изображения на наличие повреждений. Результаты обработки включают отображение исходного изображения с нанесенными ограничивающими рамками и метками обнаруженных повреждений, а также сводный список обнаруженных тегов повреждений для всего автомобиля.\n",
        "\n",
        "Интерфейс приложения стилизован для приближения к дизайну в стиле Indrive.\n",
        "\n",
        "## Требования\n",
        "\n",
        "*   Python 3.7+\n",
        "*   `gradio`\n",
        "*   `ultralytics`\n",
        "*   `Pillow`\n",
        "*   `torch` и `torchvision` (для работы `ultralytics`)\n",
        "*   `npx localtunnel` (для запуска в Google Colab с публичным доступом)\n",
        "\n",
        "## Установка\n",
        "\n",
        "1.  **Клонируйте репозиторий (если применимо) или загрузите файлы проекта.**\n",
        "2.  **Установите необходимые библиотеки Python:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "027756a0"
      },
      "source": [
        "    interface.launch(share=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "852cff66"
      },
      "source": [
        "    !curl ipecho.net/plain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db175d43"
      },
      "source": [
        "    python app.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ed84e06"
      },
      "source": [
        "## Стилизация (опционально)\n",
        "\n",
        "### Subtask:\n",
        "Попробуйте применить базовую стилизацию, чтобы приблизиться к дизайну в стиле Indrive, насколько это возможно средствами Gradio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d8e7fef"
      },
      "source": [
        "**Reasoning**:\n",
        "I will explore the available Gradio themes and potentially add custom CSS to the interface to attempt to match the Indrive style as much as possible within the constraints of Gradio's styling capabilities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b13c463"
      },
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Assume process_car_images function is defined in a previous step\n",
        "\n",
        "def process_for_gradio(image1, image2, image3, image4, image5, car_make, license_plate):\n",
        "    \"\"\"\n",
        "    Wrapper function to process images for Gradio output.\n",
        "    Takes up to 5 Gradio Image components and returns a list of annotated images\n",
        "    and a formatted string of tags.\n",
        "    \"\"\"\n",
        "    image_list = [img for img in [image1, image2, image3, image4, image5] if img is not None]\n",
        "\n",
        "    if not image_list:\n",
        "        # Return placeholders for outputs if no images are uploaded\n",
        "        return None, None, None, None, None, \"Пожалуйста, загрузите хотя бы одно изображение.\"\n",
        "\n",
        "    # Process images using the core logic (assuming process_car_images is available)\n",
        "    # Note: In a real app, you might want to handle model loading more efficiently\n",
        "    # (e.g., load once outside this function).\n",
        "    try:\n",
        "        processing_results = process_car_images(image_list, car_make, license_plate)\n",
        "    except NameError:\n",
        "        # Handle case where process_car_images is not defined (e.g., running this cell alone)\n",
        "        return None, None, None, None, None, \"Ошибка: Функция обработки изображений не определена.\"\n",
        "    except Exception as e:\n",
        "         return None, None, None, None, None, f\"Ошибка обработки: {e}\"\n",
        "\n",
        "\n",
        "    output_images = []\n",
        "    output_tags = []\n",
        "\n",
        "    # Prepare output for Gradio\n",
        "    for i, result in enumerate(processing_results):\n",
        "        if result.get('original_image'):\n",
        "            # Annotate the image with bounding boxes and class names\n",
        "            annotated_image = result['original_image'].copy()\n",
        "            draw = ImageDraw.Draw(annotated_image)\n",
        "            font = None # Use default font\n",
        "\n",
        "            # Try to load a font\n",
        "            try:\n",
        "                font_size = max(10, annotated_image.width // 50) # Dynamic font size\n",
        "                font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", font_size) # Use a common font\n",
        "            except IOError:\n",
        "                try:\n",
        "                     font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\", font_size)\n",
        "                except IOError:\n",
        "                    print(\"Font file not found, using default PIL font.\")\n",
        "                    font = ImageFont.load_default()\n",
        "\n",
        "            for box_info in result.get('boxes', []):\n",
        "                xyxy = box_info['xyxy']\n",
        "                class_name = box_info['class_name']\n",
        "                confidence = box_info['confidence']\n",
        "                label = f\"{class_name}: {confidence:.2f}\"\n",
        "\n",
        "                # Draw bounding box\n",
        "                draw.rectangle(xyxy, outline=\"red\", width=2)\n",
        "\n",
        "                # Draw label background and text\n",
        "                try:\n",
        "                    text_width, text_height = draw.textbbox((0, 0), label, font=font)[2:]\n",
        "                except AttributeError: # Handle older PIL versions without textbbox\n",
        "                     text_width, text_height = draw.textsize(label, font=font)\n",
        "\n",
        "\n",
        "                # Adjust position to stay within image bounds\n",
        "                text_x = xyxy[0]\n",
        "                text_y = xyxy[1] - text_height - 5 # Position above the box\n",
        "\n",
        "                if text_y < 0: # If text is above top edge, put it below\n",
        "                    text_y = xyxy[1] + 5\n",
        "                    # If still outside, adjust x to center if possible\n",
        "                    if text_y + text_height > annotated_image.height:\n",
        "                         text_x = xyxy[0] + (xyxy[2] - xyxy[0]) / 2 - text_width / 2\n",
        "                         text_y = xyxy[1] + 5 # Still below the box\n",
        "\n",
        "                # Ensure text_x is also within bounds\n",
        "                if text_x < 0: text_x = 0\n",
        "                if text_x + text_width > annotated_image.width: text_x = annotated_image.width - text_width\n",
        "\n",
        "\n",
        "                draw.rectangle([text_x, text_y, text_x + text_width, text_y + text_height], fill=\"red\")\n",
        "                draw.text((text_x, text_y), label, fill=\"white\", font=font)\n",
        "\n",
        "\n",
        "            output_images.append(annotated_image)\n",
        "        else:\n",
        "            output_images.append(None) # Append None if processing failed\n",
        "\n",
        "        # Format tags for display\n",
        "        tags = result.get('tags', [])\n",
        "        if tags:\n",
        "            output_tags.append(f\"Изображение {i+1}: {', '.join(tags)}\")\n",
        "        elif result.get('error'):\n",
        "             output_tags.append(f\"Изображение {i+1}: Ошибка обработки - {result['error']}\")\n",
        "        else:\n",
        "            output_tags.append(f\"Изображение {i+1}: Повреждения не обнаружены\")\n",
        "\n",
        "\n",
        "    # Combine all tag strings\n",
        "    all_tags_string = \"\\\\n\".join(output_tags)\n",
        "\n",
        "    # Gradio expects a fixed number of outputs.\n",
        "    # If we expect up to 5 images, return a list of 5 images and the tags string.\n",
        "    # Pad the output_images list with None if fewer than 5 images were uploaded.\n",
        "    while len(output_images) < 5:\n",
        "        output_images.append(None)\n",
        "\n",
        "\n",
        "    return output_images[0], output_images[1], output_images[2], output_images[3], output_images[4], all_tags_string\n",
        "\n",
        "\n",
        "# Define custom CSS to attempt Indrive-like styling\n",
        "# This is a basic attempt; a full Indrive style would be complex\n",
        "custom_css = \"\"\"\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';\n",
        "    background-color: #f0f2f5; /* Light grey background */\n",
        "    color: #333; /* Dark grey text */\n",
        "}\n",
        "h1, h2, h3, h4, h5, h6 {\n",
        "    color: #007bff; /* Indrive blue-ish color for headings */\n",
        "}\n",
        ".gradio-container {\n",
        "    box-shadow: 0 4px 8px rgba(0,0,0,0.1); /* Subtle shadow */\n",
        "    border-radius: 8px;\n",
        "    padding: 20px;\n",
        "    background-color: #ffffff; /* White background for the container */\n",
        "}\n",
        "/* Style for text inputs */\n",
        ".gr-textbox textarea {\n",
        "    border-color: #ced4da;\n",
        "    border-radius: 4px;\n",
        "    padding: 10px;\n",
        "}\n",
        "/* Style for buttons */\n",
        ".gr-button {\n",
        "    background-color: #007bff; /* Indrive blue-ish color */\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 4px;\n",
        "    padding: 10px 20px;\n",
        "    font-size: 16px;\n",
        "    cursor: pointer;\n",
        "    transition: background-color 0.3s ease;\n",
        "}\n",
        ".gr-button:hover {\n",
        "    background-color: #0056b3; /* Darker blue on hover */\n",
        "}\n",
        "/* Style for file upload area */\n",
        ".gr-upload-text {\n",
        "    color: #007bff; /* Indrive blue-ish color */\n",
        "}\n",
        "/* Style for labels */\n",
        ".gr-label {\n",
        "    font-weight: bold;\n",
        "    color: #555;\n",
        "}\n",
        "/* Style for output text */\n",
        ".gr-text output {\n",
        "    white-space: pre-wrap; /* Preserve line breaks in output */\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Define the Gradio interface with custom CSS and potentially a different theme\n",
        "interface = gr.Interface(\n",
        "    fn=process_for_gradio,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 1\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 2\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 3\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 4\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 5\"),\n",
        "        gr.Textbox(label=\"Марка автомобиля\"),\n",
        "        gr.Textbox(label=\"Госномер\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Результат обработки 1\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 2\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 3\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 4\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 5\", interactive=False),\n",
        "        gr.Textbox(label=\"Обнаруженные теги и информация\"),\n",
        "    ],\n",
        "    title=\"Приложение для определения повреждений автомобиля (Indrive Style)\",\n",
        "    description=\"Загрузите фотографии автомобиля, укажите марку и госномер для определения повреждений.\",\n",
        "    css=custom_css, # Apply custom CSS\n",
        "    # Explore different built-in themes if needed:\n",
        "    # theme=gr.themes.Soft()\n",
        "    # theme=gr.themes.Glass()\n",
        "    # theme=gr.themes.Monochrome()\n",
        "    # theme=\"default\" # Keep default or try others\n",
        ")\n",
        "\n",
        "# The interface can be launched using interface.launch()\n",
        "# In this notebook environment, we might just define it here.\n",
        "# The launch command was in the previous step."
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0723b64a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The required libraries, including `gradio` and `Pillow`, were already installed in the environment. The presence of `ultralytics` and `torch` was inferred from the context of the task.\n",
        "*   A Python function `process_car_images` was successfully defined to handle image loading, multi-model YOLO object detection, extraction of detected class names, and determination of damage-related tags (`битый`, `царапина`). It also includes error handling for individual image processing.\n",
        "*   A wrapper function `process_for_gradio` was created to adapt the core processing logic for the Gradio interface, handling multiple image inputs, annotating images with bounding boxes and labels using PIL, and formatting the output tags.\n",
        "*   The Gradio web interface was successfully defined using `gr.Interface`, including components for uploading up to five images (`gr.Image`), inputting car make and license plate (`gr.Textbox`), and displaying processed images (`gr.Image`) and detected tags (`gr.Textbox`).\n",
        "*   The core processing function (`process_for_gradio`) was successfully linked to the Gradio interface function call (`fn=process_for_gradio`).\n",
        "*   The Gradio application was successfully launched, generating a public shareable URL for external access.\n",
        "*   Basic custom CSS was applied to the Gradio interface to attempt a visual approximation of the Indrive style, modifying colors, fonts, and component appearance.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Further refinement of the styling with more detailed CSS could bring the interface closer to the target Indrive design.\n",
        "*   Implementing more robust error handling and user feedback within the Gradio interface could improve usability.\n"
      ]
    }
  ]
}