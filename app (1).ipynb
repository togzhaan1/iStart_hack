{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eus-_UvigUmZ",
        "outputId": "65a2f239-f3a3-44da-e41b-0d88a22b2a39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.199-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.199-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.199 ultralytics-thop-2.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUNEQNXLdspQ",
        "outputId": "f4f02c8b-7a8a-4092-cc1e-09ef306a5d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Проверка модель 1: /content/3.pt ---\n",
            "\n",
            "image 1/1 /content/test1.jpg: 448x640 4 Scratchs, 150.3ms\n",
            "Speed: 5.5ms preprocess, 150.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1m/content/results/model_1\u001b[0m\n",
            "\n",
            "--- Проверка модель 2: /content/2.pt ---\n",
            "\n",
            "image 1/1 /content/test1.jpg: 448x640 4 scracths, 148.9ms\n",
            "Speed: 4.8ms preprocess, 148.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1m/content/results/model_2\u001b[0m\n",
            "\n",
            "--- Проверка модель 3: /content/1.pt ---\n",
            "\n",
            "image 1/1 /content/test1.jpg: 448x640 2 scratchs, 163.6ms\n",
            "Speed: 4.2ms preprocess, 163.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1m/content/results/model_3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "model_paths = [\n",
        "    \"/content/3.pt\",\n",
        "    \"/content/2.pt\",\n",
        "    \"/content/1.pt\"\n",
        "]\n",
        "\n",
        "\n",
        "image_path = \"/content/test1.jpg\"\n",
        "\n",
        "for i, path in enumerate(model_paths, start=1):\n",
        "    print(f\"\\n--- Проверка модель {i}: {path} ---\")\n",
        "    model = YOLO(path)\n",
        "    results = model.predict(\n",
        "        source=image_path,\n",
        "        conf=0.2,\n",
        "        save=True,\n",
        "        project=\"/content/results\",   # папка куда сохранять\n",
        "        name=f\"model_{i}\",            # подпапка для каждой модели\n",
        "        exist_ok=True                 # чтобы не ругался на существующие папки\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bf4faee",
        "outputId": "20b7c6bd-dfa1-4d43-a273-ff90725a4850"
      },
      "source": [
        "!pip install gradio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.44.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.17.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55e71ff3"
      },
      "source": [
        "import io\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import os # Import os to get basename of model path\n",
        "\n",
        "def process_car_images(image_files, car_make, license_plate):\n",
        "    \"\"\"\n",
        "    Processes car images using YOLO models to detect damages and tags.\n",
        "\n",
        "    Args:\n",
        "        image_files (list): A list of file paths or file-like objects (e.g., from Gradio).\n",
        "        car_make (str): The make of the car.\n",
        "        license_plate (str): The license plate number of the car.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains the\n",
        "              original image (as a PIL Image), car make, license plate,\n",
        "              detected tags, and optionally the detected bounding boxes.\n",
        "    \"\"\"\n",
        "    model_paths = [\n",
        "        \"/content/3.pt\", # Example model path for damage detection\n",
        "        \"/content/2.pt\", # Example model path for rust detection\n",
        "        \"/content/1.pt\"  # Example model path for scratch detection\n",
        "    ]\n",
        "\n",
        "    # Load models once\n",
        "    models = []\n",
        "    for path in model_paths:\n",
        "        try:\n",
        "            model = YOLO(path)\n",
        "            models.append(model)\n",
        "            # print(f\"Successfully loaded model: {path}\") # Keep for debugging if needed\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {path}: {e}\") # Print model loading errors\n",
        "            # If a model fails to load, we can't use it for predictions.\n",
        "            # The list 'models' will only contain successfully loaded models.\n",
        "\n",
        "\n",
        "    results_data = []\n",
        "\n",
        "    for i, image_file in enumerate(image_files):\n",
        "        try:\n",
        "            # print(f\"Processing image {i+1}...\") # Keep for debugging if needed\n",
        "            # Load the image - handle different input types from Gradio\n",
        "            image = None\n",
        "            if isinstance(image_file, Image.Image):\n",
        "                image = image_file.convert(\"RGB\")\n",
        "                # print(f\"Processing image {i+1} from PIL Image object\") # Keep for debugging if needed\n",
        "            elif isinstance(image_file, (str, bytes)): # Handle file paths or bytes\n",
        "                 try:\n",
        "                     if isinstance(image_file, str):\n",
        "                          image = Image.open(image_file).convert(\"RGB\")\n",
        "                     elif isinstance(image_file, bytes):\n",
        "                          image = Image.open(io.BytesIO(image_file)).convert(\"RGB\")\n",
        "                     # print(f\"Loaded image {i+1} from path/bytes\") # Keep for debugging if needed\n",
        "                 except Exception as img_load_e:\n",
        "                     raise IOError(f\"Failed to load image {i+1}: {img_load_e}\") from img_load_e\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported image file type for image {i+1}: {type(image_file)}\")\n",
        "\n",
        "\n",
        "            detected_tags = set()\n",
        "            detections = []\n",
        "            all_boxes = [] # To store bounding boxes for potential visualization\n",
        "\n",
        "            if image is not None:\n",
        "                # Process image with each successfully loaded model\n",
        "                for model in models:\n",
        "                    model_path = getattr(model, 'ckpt_path', 'unknown_model') # Get model path if available\n",
        "                    try:\n",
        "                        # print(f\"Running prediction on image {i+1} with model {model_path}...\") # Keep for debugging if needed\n",
        "                        # Perform prediction\n",
        "                        results = model.predict(\n",
        "                            source=image,\n",
        "                            conf=0.2, # Confidence threshold\n",
        "                            save=False, # Don't save images to disk\n",
        "                            verbose=False # Suppress verbose output\n",
        "                        )\n",
        "                        # print(f\"Prediction successful for image {i+1} with model {os.path.basename(model_path)}.\") # Keep for debugging if needed\n",
        "\n",
        "\n",
        "                        # Process results from the current model\n",
        "                        for r in results:\n",
        "                            if r.boxes is not None and len(r.boxes) > 0:\n",
        "                                for box in r.boxes:\n",
        "                                    class_id = int(box.cls)\n",
        "                                    class_name = model.names[class_id]\n",
        "                                    detections.append(class_name)\n",
        "                                    # Store box coordinates and class name\n",
        "                                    all_boxes.append({\n",
        "                                        'xyxy': box.xyxy[0].tolist(), # Bounding box coordinates [x1, y1, x2, y2]\n",
        "                                        'class_name': class_name,\n",
        "                                        'confidence': float(box.conf)\n",
        "                                    })\n",
        "                                # print(f\"Detected {len(r.boxes)} objects for image {i+1} with model {os.path.basename(model_path)}. Detections: {detections}\") # Keep for debugging if needed\n",
        "                            # else:\n",
        "                                # print(f\"No objects detected for image {i+1} with model {os.path.basename(model_path)}.\") # Keep for debugging if needed\n",
        "\n",
        "\n",
        "                    except Exception as model_e:\n",
        "                        print(f\"Error during prediction for image {i+1} with model {os.path.basename(model_path)}: {model_e}\") # Print prediction errors\n",
        "                        # Add an error tag for the specific model that failed prediction\n",
        "                        detected_tags.add(f\"Ошибка модели {os.path.basename(model_path)}: {model_e}\")\n",
        "\n",
        "\n",
        "            # Determine tags based on detections across all models\n",
        "            # Filter out error tags before determining main damage tags\n",
        "            actual_detections = [d for d in detections if not d.startswith('Ошибка модели')]\n",
        "\n",
        "            if 'rust' in actual_detections or 'dented' in actual_detections or 'broken' in actual_detections: # Adjust based on your model's classes\n",
        "                 detected_tags.add('битый')\n",
        "            if 'scratch' in actual_detections: # Adjust based on your model's classes\n",
        "                detected_tags.add('царапина')\n",
        "            # Add logic for 'грязный' if you have a model for it or another criteria\n",
        "\n",
        "            # Ensure original image is included in the result only if processing was mostly successful\n",
        "            # (i.e., image loaded and models were available)\n",
        "            result_image = image if image is not None else None\n",
        "\n",
        "            results_data.append({\n",
        "                'original_image': result_image, # Store the PIL Image object or None if loading failed\n",
        "                'car_make': car_make,\n",
        "                'license_plate': license_plate,\n",
        "                'tags': list(detected_tags), # Convert set to list\n",
        "                'detections': actual_detections, # List of all detected class names (excluding errors)\n",
        "                'boxes': all_boxes, # List of bounding box details\n",
        "                'error': None # No general processing error if we reached this point\n",
        "            })\n",
        "            # print(f\"Finished processing image {i+1}. Tags: {detected_tags}\") # Keep for debugging if needed\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"General error processing image {i+1}: {e}\") # Print any other general processing errors\n",
        "            # Append an entry indicating processing failed for this image\n",
        "            results_data.append({\n",
        "                'original_image': None, # Indicate failure\n",
        "                'car_make': car_make,\n",
        "                'license_plate': license_plate,\n",
        "                'tags': [f'Общая ошибка обработки: {e}'], # Include general error message in tag\n",
        "                'detections': [],\n",
        "                'boxes': [],\n",
        "                'error': str(e) # Store the error message\n",
        "            })\n",
        "\n",
        "\n",
        "    # print(\"\\n--- Final results_data ---\") # Keep for debugging if needed\n",
        "    # for i, result in enumerate(results_data): # Keep for debugging if needed\n",
        "    #     print(f\"Image {i+1}:\") # Keep for debugging if needed\n",
        "    #     print(f\"  Car Make: {result.get('car_make')}\") # Keep for debugging if needed\n",
        "    #     print(f\"  License Plate: {result.get('license_plate')}\") # Keep for debugging if needed\n",
        "    #     print(f\"  Tags: {result.get('tags')}\") # Keep for debugging if needed\n",
        "    #     print(f\"  Detections: {result.get('detections')}\") # Keep for debugging if needed\n",
        "    #     print(f\"  Boxes: {len(result.get('boxes', []))} detected boxes\") # Keep for debugging if needed\n",
        "    #     if result.get('error'): # Keep for debugging if needed\n",
        "    #         print(f\"  Error: {result['error']}\") # Keep for debugging if needed\n",
        "    # print(\"--------------------------\\n\") # Keep for debugging if needed\n",
        "\n",
        "\n",
        "    return results_data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPP8VyHOnuqX"
      },
      "source": [
        "import gradio as gr\n",
        "import io\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Assume process_car_images function is defined in the previous step\n",
        "\n",
        "def process_for_gradio(image1, image2, image3, image4, image5, car_make, license_plate):\n",
        "    \"\"\"\n",
        "    Wrapper function to process images for Gradio output.\n",
        "    Takes up to 5 Gradio Image components and returns a list of annotated images\n",
        "    and a formatted string of tags.\n",
        "    \"\"\"\n",
        "    # Collect non-None images and ensure they are PIL Image objects if possible\n",
        "    image_list = []\n",
        "    for img in [image1, image2, image3, image4, image5]:\n",
        "        if img is not None:\n",
        "            if isinstance(img, Image.Image):\n",
        "                image_list.append(img)\n",
        "            # Add other type checks if Gradio might pass other formats (e.g., numpy arrays, file paths)\n",
        "            # For Gradio's Image component with type=\"pil\", it should ideally pass PIL Image.\n",
        "            else:\n",
        "                 print(f\"Warning: Unexpected image format received by Gradio wrapper: {type(img)}\")\n",
        "                 # Attempt to convert if it's a path or bytes, though type=\"pil\" should handle this\n",
        "                 try:\n",
        "                     if isinstance(img, str): # Assuming it might be a file path\n",
        "                          image_list.append(Image.open(img).convert(\"RGB\"))\n",
        "                     elif isinstance(img, bytes): # Assuming it might be bytes\n",
        "                          image_list.append(Image.open(io.BytesIO(img)).convert(\"RGB\"))\n",
        "                     # Add other conversions if necessary\n",
        "                     else:\n",
        "                          print(f\"Error: Cannot process image of type {type(img)}\")\n",
        "                          # Optionally add an error entry to results_data here if conversion fails\n",
        "                 except Exception as e:\n",
        "                      print(f\"Error converting image type: {e}\")\n",
        "                      # Optionally add an error entry to results_data here if conversion fails\n",
        "\n",
        "\n",
        "    if not image_list:\n",
        "        # Return placeholders for outputs if no images are uploaded\n",
        "        # Also return empty string for overall tags\n",
        "        return None, None, None, None, None, \"\", \"Пожалуйста, загрузите хотя бы одно изображение.\"\n",
        "\n",
        "    # Process images using the core logic\n",
        "    # The process_car_images function is expected to handle a list of PIL Image objects\n",
        "    try:\n",
        "        processing_results = process_car_images(image_list, car_make, license_plate)\n",
        "    except NameError:\n",
        "        # Handle case where process_car_images is not defined (e.g., running this cell alone)\n",
        "        return None, None, None, None, None, \"\", \"Ошибка: Функция обработки изображений не определена.\"\n",
        "    except Exception as e:\n",
        "         return None, None, None, None, None, \"\", f\"Общая ошибка обработки: {e}\"\n",
        "\n",
        "\n",
        "    output_images = []\n",
        "    output_individual_tags = []\n",
        "    overall_tags_set = set() # Set to store unique overall tags\n",
        "\n",
        "    # Prepare output for Gradio\n",
        "    for i, result in enumerate(processing_results):\n",
        "        # Check if processing was successful for this image\n",
        "        if result.get('original_image') and not result.get('error'):\n",
        "            # Annotate the image with bounding boxes and class names\n",
        "            annotated_image = result['original_image'].copy()\n",
        "            draw = ImageDraw.Draw(annotated_image)\n",
        "            font = None # Use default font\n",
        "\n",
        "            # Try to load a font\n",
        "            try:\n",
        "                font_size = max(10, annotated_image.width // 50) # Dynamic font size\n",
        "                # Use fonts commonly available in Colab\n",
        "                font_paths = [\"DejaVuSans-Bold.ttf\", \"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\"]\n",
        "                for font_path in font_paths:\n",
        "                    try:\n",
        "                        font = ImageFont.truetype(font_path, font_size)\n",
        "                        break # Found a font, exit loop\n",
        "                    except IOError:\n",
        "                        continue # Try next font\n",
        "\n",
        "                if font is None:\n",
        "                     print(\"Warning: Font file not found, using default PIL font.\")\n",
        "                     font = ImageFont.load_default()\n",
        "\n",
        "\n",
        "            except Exception as font_e:\n",
        "                print(f\"Error loading font: {font_e}\")\n",
        "                font = ImageFont.load_default() # Fallback to default font\n",
        "\n",
        "\n",
        "            for box_info in result.get('boxes', []):\n",
        "                xyxy = box_info['xyxy']\n",
        "                class_name = box_info['class_name']\n",
        "                confidence = box_info['confidence']\n",
        "                label = f\"{class_name}: {confidence:.2f}\"\n",
        "\n",
        "                # Draw bounding box\n",
        "                draw.rectangle(xyxy, outline=\"red\", width=2)\n",
        "\n",
        "                # Draw label background and text\n",
        "                try:\n",
        "                    text_width, text_height = draw.textbbox((0, 0), label, font=font)[2:]\n",
        "                except AttributeError: # Handle older PIL versions without textbbox\n",
        "                     text_width, text_height = draw.textsize(label, font=font)\n",
        "\n",
        "\n",
        "                # Adjust position to stay within image bounds\n",
        "                text_x = xyxy[0]\n",
        "                text_y = xyxy[1] - text_height - 5 # Position above the box\n",
        "\n",
        "                if text_y < 0: # If text is above top edge, put it below\n",
        "                    text_y = xyxy[1] + 5\n",
        "                    # If still outside, adjust x to center if possible\n",
        "                    if text_y + text_height > annotated_image.height:\n",
        "                         text_x = xyxy[0] + (xyxy[2] - xyxy[0]) / 2 - text_width / 2\n",
        "                         text_y = xyxy[1] + 5 # Still below the box\n",
        "\n",
        "                # Ensure text_x is also within bounds\n",
        "                if text_x < 0: text_x = 0\n",
        "                if text_x + text_width > annotated_image.width: text_x = annotated_image.width - text_width\n",
        "\n",
        "                try:\n",
        "                    draw.rectangle([text_x, text_y, text_x + text_width, text_y + text_height], fill=\"red\")\n",
        "                    draw.text((text_x, text_y), label, fill=\"white\", font=font)\n",
        "                except Exception as draw_e:\n",
        "                    print(f\"Error drawing on image: {draw_e}\")\n",
        "\n",
        "\n",
        "            output_images.append(annotated_image)\n",
        "\n",
        "            # Add individual image tags to the list\n",
        "            tags = result.get('tags', [])\n",
        "            if tags:\n",
        "                output_individual_tags.append(f\"Изображение {i+1}: {', '.join(tags)}\")\n",
        "                # Add tags to the overall set (excluding error tags for overall summary)\n",
        "                overall_tags_set.update([t for t in tags if not t.startswith('Ошибка')])\n",
        "            else:\n",
        "                output_individual_tags.append(f\"Изображение {i+1}: Повреждения не обнаружены\")\n",
        "\n",
        "        else:\n",
        "            # If processing failed or no image was returned, append None\n",
        "            output_images.append(None)\n",
        "            # Report error for this specific image\n",
        "            error_msg = result.get('error', 'Неизвестная ошибка')\n",
        "            output_individual_tags.append(f\"Изображение {i+1}: Ошибка обработки - {error_msg}\")\n",
        "            # Add general error tag to overall tags if applicable\n",
        "            overall_tags_set.add(\"Общая ошибка обработки\")\n",
        "\n",
        "\n",
        "    # Filter overall tags to include only \"битый\" and \"грязный\" and format for display\n",
        "    filtered_overall_tags = []\n",
        "    if 'битый' in overall_tags_set:\n",
        "        filtered_overall_tags.append('БИТЫЙ')\n",
        "    if 'грязный' in overall_tags_set:\n",
        "        filtered_overall_tags.append('ГРЯЗНЫЙ')\n",
        "    # Add other specific tags if needed, e.g., for errors\n",
        "    if 'Общая ошибка обработки' in overall_tags_set:\n",
        "         filtered_overall_tags.append('Общая ошибка обработки') # Include general error tag\n",
        "\n",
        "\n",
        "    overall_tags_string = \"Общие теги повреждений: \" + (\", \".join(filtered_overall_tags) if filtered_overall_tags else \"Нет обнаружено\")\n",
        "    individual_tags_string = \"\\\\n\".join(output_individual_tags)\n",
        "\n",
        "    # Combine overall and individual tags in the final output string\n",
        "    final_tags_output = f\"{overall_tags_string}\\\\n\\\\nРезультаты по изображениям:\\\\n{individual_tags_string}\"\n",
        "\n",
        "\n",
        "    # Gradio expects a fixed number of outputs.\n",
        "    # If we expect up to 5 images, return a list of 5 images and the tags string.\n",
        "    # Pad the output_images list with None if fewer than 5 images were processed successfully.\n",
        "    while len(output_images) < 5:\n",
        "        output_images.append(None)\n",
        "\n",
        "\n",
        "    # Return the 5 images and the combined tag string\n",
        "    return output_images[0], output_images[1], output_images[2], output_images[3], output_images[4], final_tags_output\n",
        "\n",
        "\n",
        "# Define the Gradio interface\n",
        "# Use multiple Image components for output, up to a reasonable number (e.g., 5)\n",
        "# The custom CSS is defined in the previous step and will be applied when the interface is launched.\n",
        "interface = gr.Interface(\n",
        "    fn=process_for_gradio,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 1\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 2\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 3\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 4\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 5\"),\n",
        "        gr.Textbox(label=\"Марка автомобиля\"),\n",
        "        gr.Textbox(label=\"Госномер\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Результат обработки 1\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 2\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 3\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 4\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 5\", interactive=False),\n",
        "        gr.Textbox(label=\"Обнаруженные теги и информация\"),\n",
        "    ],\n",
        "    title=\"Приложение для определения повреждений автомобиля (Indrive Style)\",\n",
        "    description=\"Загрузите фотографии автомобиля, укажите марку и госномер для определения повреждений.\",\n",
        "    css=\"\"\"\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';\n",
        "    background-color: #f0f2f5; /* Light grey background */\n",
        "    color: #333; /* Dark grey text */\n",
        "}\n",
        "h1, h2, h3, h4, h5, h6 {\n",
        "    color: #007bff; /* Indrive blue-ish color for headings */\n",
        "}\n",
        ".gradio-container {\n",
        "    box-shadow: 0 4px 8px rgba(0,0,0,0.1); /* Subtle shadow */\n",
        "    border-radius: 8px;\n",
        "    padding: 20px;\n",
        "    background-color: #ffffff; /* White background for the container */\n",
        "}\n",
        "/* Style for text inputs */\n",
        ".gr-textbox textarea {\n",
        "    border-color: #ced4da;\n",
        "    border-radius: 4px;\n",
        "    padding: 10px;\n",
        "}\n",
        "/* Style for buttons */\n",
        ".gr-button {\n",
        "    background-color: #007bff; /* Indrive blue-ish color */\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 4px;\n",
        "    padding: 10px 20px;\n",
        "    font-size: 16px;\n",
        "    cursor: pointer;\n",
        "    transition: background-color 0.3s ease;\n",
        "}\n",
        ".gr-button:hover {\n",
        "    background-color: #0056b3; /* Darker blue on hover */\n",
        "}\n",
        "/* Style for file upload area */\n",
        ".gr-upload-text {\n",
        "    color: #007bff; /* Indrive blue-ish color */\n",
        "}\n",
        "/* Style for labels */\n",
        ".gr-label {\n",
        "    font-weight: bold;\n",
        "    color: #555;\n",
        "}\n",
        "/* Style for output text */\n",
        ".gr-text output {\n",
        "    white-space: pre-wrap; /* Preserve line breaks in output */\n",
        "}\n",
        "\"\"\", # Apply custom CSS directly\n",
        "    # theme=gr.themes.Soft() # Example of applying a built-in theme\n",
        ")\n",
        "\n",
        "# The interface can be launched using interface.launch()\n",
        "# The launch command is in a separate cell."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "d6a9551c",
        "outputId": "ea71a322-0f77-4ccc-8e69-9bbd1d6bc924"
      },
      "source": [
        "interface.launch(share=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
            "----\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://11d68f6cd7628479c8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://11d68f6cd7628479c8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bd8295b"
      },
      "source": [
        "# Приложение для определения повреждений автомобиля (Indrive Style)\n",
        "\n",
        "Это веб-приложение, созданное с использованием Gradio и YOLO моделей, для загрузки фотографий автомобилей, определения типов повреждений (таких как \"битый\", \"царапина\", \"грязный\") и отображения результатов.\n",
        "\n",
        "## Описание\n",
        "\n",
        "Приложение позволяет пользователям загружать несколько фотографий автомобиля и предоставлять основную информацию (марка, госномер). Затем оно использует предобученные YOLO модели для анализа каждого изображения на наличие повреждений. Результаты обработки включают отображение исходного изображения с нанесенными ограничивающими рамками и метками обнаруженных повреждений, а также сводный список обнаруженных тегов повреждений для всего автомобиля.\n",
        "\n",
        "Интерфейс приложения стилизован для приближения к дизайну в стиле Indrive.\n",
        "\n",
        "## Требования\n",
        "\n",
        "* Python 3.7+\n",
        "* `gradio`\n",
        "* `ultralytics`\n",
        "* `Pillow`\n",
        "* `torch` и `torchvision` (для работы `ultralytics`)\n",
        "\n",
        "## Установка и Запуск в Google Colab\n",
        "\n",
        "Для запуска приложения в Google Colab выполните следующие шаги по порядку:\n",
        "\n",
        "1. **Установка библиотек:** Выполните первую ячейку кода в ноутбуке, чтобы установить библиотеку `ultralytics`.\n",
        "2. **Загрузка моделей:** Убедитесь, что файлы ваших обученных YOLO моделей (например, `3.pt`, `2.pt`, `1.pt`) загружены в каталог `/content/` в вашей среде выполнения Colab. Вы можете загрузить их, используя значок папки на левой боковой панели Colab, перейдя в каталог `/content/` и нажав кнопку \"Загрузить\".\n",
        "3. **Запуск предсказаний (опционально для проверки):** Ячейка с кодом, которая импортирует `YOLO` и выполняет предсказания (`LUNEQNXLdspQ`), демонстрирует, как использовать модели для обработки изображений. Она настроена на использование моделей из `/content/`. Вы можете запустить ее, чтобы проверить, что модели работают правильно.\n",
        "4. **Установка Gradio:** Выполните ячейку кода для установки библиотеки `gradio`.\n",
        "5. **Определение функции обработки и интерфейса Gradio:** Выполните ячейку кода, которая определяет функцию `process_car_images` и `process_for_gradio`, а также сам интерфейс Gradio. Обратите внимание, что в функции `process_car_images` пути к моделям указаны как `/content/3.pt`, `/content/2.pt`, `/content/1.pt`. Убедитесь, что имена файлов моделей в `/content/` совпадают с указанными в коде.\n",
        "6. **Запуск интерфейса Gradio:** Выполните последнюю ячейку кода, чтобы запустить веб-интерфейс Gradio. После запуска появится публичная ссылка, по которой вы сможете получить доступ к приложению.\n",
        "\n",
        "## Структура проекта\n",
        "\n",
        "*   `[ваши файлы моделей]`: Файлы обученных YOLO моделей (например, `3.pt`, `2.pt`, `1.pt`), которые должны быть загружены в `/content/`.\n",
        "*   `[ваш файл изображения]`: Тестовое изображение (например, `test1.jpg`), которое может быть загружено в `/content/` для проверки.\n",
        "*   Ячейки кода в ноутбуке:\n",
        "    *   Установка `ultralytics`.\n",
        "    *   Пример использования моделей для предсказания на тестовом изображении (опционально).\n",
        "    *   Установка `gradio`.\n",
        "    *   Определение функций обработки изображений и интерфейса Gradio.\n",
        "    *   Запуск интерфейса Gradio.\n",
        "\n",
        "## Использование\n",
        "\n",
        "1.  Загрузите фотографии автомобиля с помощью элементов \"Загрузите фото автомобиля\".\n",
        "2.  Введите марку автомобиля и госномер в соответствующие текстовые поля.\n",
        "3.  Нажмите кнопку \"Submit\" (или аналогичную, в зависимости от языка интерфейса Gradio).\n",
        "4.  В разделе результатов вы увидите обработанные изображения с обнаруженными повреждениями и список обнаруженных тегов.\n",
        "\n",
        "## Стилизация\n",
        "\n",
        "Приложение включает базовую стилизацию с использованием CSS, чтобы придать интерфейсу вид, близкий к стилю Indrive. Вы можете модифицировать CSS в коде интерфейса Gradio для дальнейшей настройки."
      ]
    }
  ]
}