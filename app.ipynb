{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eus-_UvigUmZ",
        "outputId": "65a2f239-f3a3-44da-e41b-0d88a22b2a39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.199-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.199-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.199 ultralytics-thop-2.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUNEQNXLdspQ",
        "outputId": "dcee271b-2aff-429b-af18-4f09217d0822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Проверка модель 1: /content/3.pt ---\n",
            "\n",
            "image 1/1 /content/test1.jpg: 384x640 (no detections), 290.2ms\n",
            "Speed: 16.8ms preprocess, 290.2ms inference, 19.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/results/model_1\u001b[0m\n",
            "\n",
            "--- Проверка модель 2: /content/2.pt ---\n",
            "\n",
            "image 1/1 /content/test1.jpg: 384x640 1 rust, 133.8ms\n",
            "Speed: 3.9ms preprocess, 133.8ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/results/model_2\u001b[0m\n",
            "\n",
            "--- Проверка модель 3: /content/1.pt ---\n",
            "\n",
            "image 1/1 /content/test1.jpg: 384x640 2 scratchs, 123.5ms\n",
            "Speed: 3.4ms preprocess, 123.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/results/model_3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "model_paths = [\n",
        "    \"/content/3.pt\",\n",
        "    \"/content/2.pt\",\n",
        "    \"/content/1.pt\"\n",
        "]\n",
        "\n",
        "\n",
        "image_path = \"/content/test1.jpg\"\n",
        "\n",
        "for i, path in enumerate(model_paths, start=1):\n",
        "    print(f\"\\n--- Проверка модель {i}: {path} ---\")\n",
        "    model = YOLO(path)\n",
        "    results = model.predict(\n",
        "        source=image_path,\n",
        "        conf=0.2,\n",
        "        save=True,\n",
        "        project=\"/content/results\",   # папка куда сохранять\n",
        "        name=f\"model_{i}\",            # подпапка для каждой модели\n",
        "        exist_ok=True                 # чтобы не ругался на существующие папки\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bf4faee",
        "outputId": "20b7c6bd-dfa1-4d43-a273-ff90725a4850"
      },
      "source": [
        "!pip install gradio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.44.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.17.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c3c9907"
      },
      "source": [
        "## Функция обработки изображений\n",
        "\n",
        "### Subtask:\n",
        "Создайте функцию на Python, которая будет принимать загруженное изображение, информацию о машине и использовать ваши YOLO модели для определения повреждений и тегов.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fbaa12f"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the Python function `process_car_images` that takes image files and car information, loads the YOLO models, iterates through the images and models to perform detection, determines tags based on detected classes, and structures the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55e71ff3"
      },
      "source": [
        "import io\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import os # Import os to get basename of model path\n",
        "\n",
        "def process_car_images(image_files, car_make, license_plate):\n",
        "    \"\"\"\n",
        "    Processes car images using YOLO models to detect damages and tags.\n",
        "\n",
        "    Args:\n",
        "        image_files (list): A list of file paths or file-like objects (e.g., from Gradio).\n",
        "        car_make (str): The make of the car.\n",
        "        license_plate (str): The license plate number of the car.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains the\n",
        "              original image (as a PIL Image), car make, license plate,\n",
        "              detected tags, and optionally the detected bounding boxes.\n",
        "    \"\"\"\n",
        "    model_paths = [\n",
        "        \"/content/3.pt\", # Example model path for damage detection\n",
        "        \"/content/2.pt\", # Example model path for rust detection\n",
        "        \"/content/1.pt\"  # Example model path for scratch detection\n",
        "    ]\n",
        "\n",
        "    # Load models once\n",
        "    models = []\n",
        "    for path in model_paths:\n",
        "        try:\n",
        "            model = YOLO(path)\n",
        "            models.append(model)\n",
        "            # print(f\"Successfully loaded model: {path}\") # Keep for debugging if needed\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {path}: {e}\") # Print model loading errors\n",
        "            # If a model fails to load, we can't use it for predictions.\n",
        "            # The list 'models' will only contain successfully loaded models.\n",
        "\n",
        "\n",
        "    results_data = []\n",
        "\n",
        "    for i, image_file in enumerate(image_files):\n",
        "        try:\n",
        "            # print(f\"Processing image {i+1}...\") # Keep for debugging if needed\n",
        "            # Load the image - handle different input types from Gradio\n",
        "            image = None\n",
        "            if isinstance(image_file, Image.Image):\n",
        "                image = image_file.convert(\"RGB\")\n",
        "                # print(f\"Processing image {i+1} from PIL Image object\") # Keep for debugging if needed\n",
        "            elif isinstance(image_file, (str, bytes)): # Handle file paths or bytes\n",
        "                 try:\n",
        "                     if isinstance(image_file, str):\n",
        "                          image = Image.open(image_file).convert(\"RGB\")\n",
        "                     elif isinstance(image_file, bytes):\n",
        "                          image = Image.open(io.BytesIO(image_file)).convert(\"RGB\")\n",
        "                     # print(f\"Loaded image {i+1} from path/bytes\") # Keep for debugging if needed\n",
        "                 except Exception as img_load_e:\n",
        "                     raise IOError(f\"Failed to load image {i+1}: {img_load_e}\") from img_load_e\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported image file type for image {i+1}: {type(image_file)}\")\n",
        "\n",
        "\n",
        "            detected_tags = set()\n",
        "            detections = []\n",
        "            all_boxes = [] # To store bounding boxes for potential visualization\n",
        "\n",
        "            if image is not None:\n",
        "                # Process image with each successfully loaded model\n",
        "                for model in models:\n",
        "                    model_path = getattr(model, 'ckpt_path', 'unknown_model') # Get model path if available\n",
        "                    try:\n",
        "                        # print(f\"Running prediction on image {i+1} with model {model_path}...\") # Keep for debugging if needed\n",
        "                        # Perform prediction\n",
        "                        results = model.predict(\n",
        "                            source=image,\n",
        "                            conf=0.2, # Confidence threshold\n",
        "                            save=False, # Don't save images to disk\n",
        "                            verbose=False # Suppress verbose output\n",
        "                        )\n",
        "                        # print(f\"Prediction successful for image {i+1} with model {os.path.basename(model_path)}.\") # Keep for debugging if needed\n",
        "\n",
        "\n",
        "                        # Process results from the current model\n",
        "                        for r in results:\n",
        "                            if r.boxes is not None and len(r.boxes) > 0:\n",
        "                                for box in r.boxes:\n",
        "                                    class_id = int(box.cls)\n",
        "                                    class_name = model.names[class_id]\n",
        "                                    detections.append(class_name)\n",
        "                                    # Store box coordinates and class name\n",
        "                                    all_boxes.append({\n",
        "                                        'xyxy': box.xyxy[0].tolist(), # Bounding box coordinates [x1, y1, x2, y2]\n",
        "                                        'class_name': class_name,\n",
        "                                        'confidence': float(box.conf)\n",
        "                                    })\n",
        "                                # print(f\"Detected {len(r.boxes)} objects for image {i+1} with model {os.path.basename(model_path)}. Detections: {detections}\") # Keep for debugging if needed\n",
        "                            # else:\n",
        "                                # print(f\"No objects detected for image {i+1} with model {os.path.basename(model_path)}.\") # Keep for debugging if needed\n",
        "\n",
        "\n",
        "                    except Exception as model_e:\n",
        "                        print(f\"Error during prediction for image {i+1} with model {os.path.basename(model_path)}: {model_e}\") # Print prediction errors\n",
        "                        # Add an error tag for the specific model that failed prediction\n",
        "                        detected_tags.add(f\"Ошибка модели {os.path.basename(model_path)}: {model_e}\")\n",
        "\n",
        "\n",
        "            # Determine tags based on detections across all models\n",
        "            # Filter out error tags before determining main damage tags\n",
        "            actual_detections = [d for d in detections if not d.startswith('Ошибка модели')]\n",
        "\n",
        "            if 'rust' in actual_detections or 'dented' in actual_detections or 'broken' in actual_detections: # Adjust based on your model's classes\n",
        "                 detected_tags.add('битый')\n",
        "            if 'scratch' in actual_detections: # Adjust based on your model's classes\n",
        "                detected_tags.add('царапина')\n",
        "            # Add logic for 'грязный' if you have a model for it or another criteria\n",
        "\n",
        "            # Ensure original image is included in the result only if processing was mostly successful\n",
        "            # (i.e., image loaded and models were available)\n",
        "            result_image = image if image is not None else None\n",
        "\n",
        "            results_data.append({\n",
        "                'original_image': result_image, # Store the PIL Image object or None if loading failed\n",
        "                'car_make': car_make,\n",
        "                'license_plate': license_plate,\n",
        "                'tags': list(detected_tags), # Convert set to list\n",
        "                'detections': actual_detections, # List of all detected class names (excluding errors)\n",
        "                'boxes': all_boxes, # List of bounding box details\n",
        "                'error': None # No general processing error if we reached this point\n",
        "            })\n",
        "            # print(f\"Finished processing image {i+1}. Tags: {detected_tags}\") # Keep for debugging if needed\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"General error processing image {i+1}: {e}\") # Print any other general processing errors\n",
        "            # Append an entry indicating processing failed for this image\n",
        "            results_data.append({\n",
        "                'original_image': None, # Indicate failure\n",
        "                'car_make': car_make,\n",
        "                'license_plate': license_plate,\n",
        "                'tags': [f'Общая ошибка обработки: {e}'], # Include general error message in tag\n",
        "                'detections': [],\n",
        "                'boxes': [],\n",
        "                'error': str(e) # Store the error message\n",
        "            })\n",
        "\n",
        "\n",
        "    # print(\"\\n--- Final results_data ---\") # Keep for debugging if needed\n",
        "    # for i, result in enumerate(results_data): # Keep for debugging if needed\n",
        "    #     print(f\"Image {i+1}:\") # Keep for debugging if needed\n",
        "    #     print(f\"  Car Make: {result.get('car_make')}\") # Keep for debugging if needed\n",
        "    #     print(f\"  License Plate: {result.get('license_plate')}\") # Keep for debugging if needed\n",
        "    #     print(f\"  Tags: {result.get('tags')}\") # Keep for debugging if needed\n",
        "    #     print(f\"  Detections: {result.get('detections')}\") # Keep for debugging if needed\n",
        "    #     print(f\"  Boxes: {len(result.get('boxes', []))} detected boxes\") # Keep for debugging if needed\n",
        "    #     if result.get('error'): # Keep for debugging if needed\n",
        "    #         print(f\"  Error: {result['error']}\") # Keep for debugging if needed\n",
        "    # print(\"--------------------------\\n\") # Keep for debugging if needed\n",
        "\n",
        "\n",
        "    return results_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30508c88"
      },
      "source": [
        "## Создание интерфейса gradio\n",
        "\n",
        "### Subtask:\n",
        "Используйте Gradio для создания веб-интерфейса с элементами для загрузки изображений, ввода текста (марка, госномер) и отображения результатов (изображение с разметкой, теги).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3da40541"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the Gradio interface structure to include input fields for multiple images, car make, and license plate, and output fields for displaying processed images and detected tags.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "4725e5f0",
        "outputId": "6a26afe4-2fdf-470d-8d4c-3db3590f2054"
      },
      "source": [
        "import gradio as gr\n",
        "import io\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Assume process_car_images function is defined in the previous step\n",
        "\n",
        "def process_for_gradio(image_list, car_make, license_plate):\n",
        "    \"\"\"\n",
        "    Wrapper function to process images for Gradio output.\n",
        "    Takes a list of Gradio Image components and returns a list of annotated images\n",
        "    and a formatted string of tags.\n",
        "    \"\"\"\n",
        "    if not image_list:\n",
        "        return [None] * 5, \"Пожалуйста, загрузите хотя бы одно изображение.\" # Return placeholders for outputs\n",
        "\n",
        "    # Convert Gradio Image components to PIL Images if necessary (Gradio often passes PIL Images directly)\n",
        "    # The process_car_images function expects file-like objects or paths, or PIL Images\n",
        "    # Let's assume image_list contains PIL Images passed by Gradio\n",
        "    # If Gradio passes paths or bytes, process_car_images needs to handle that.\n",
        "    # Based on typical Gradio behavior with Image component, it passes PIL.Image.Image\n",
        "\n",
        "    # Process images using the core logic\n",
        "    processing_results = process_car_images(image_list, car_make, license_plate)\n",
        "\n",
        "    output_images = []\n",
        "    output_tags = []\n",
        "\n",
        "    # Prepare output for Gradio\n",
        "    for i, result in enumerate(processing_results):\n",
        "        if result.get('original_image'):\n",
        "            # Annotate the image with bounding boxes and class names\n",
        "            annotated_image = result['original_image'].copy()\n",
        "            draw = ImageDraw.Draw(annotated_image)\n",
        "            font = None # Use default font\n",
        "\n",
        "            # Try to load a font\n",
        "            try:\n",
        "                font_size = max(10, annotated_image.width // 50) # Dynamic font size\n",
        "                font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", font_size) # Use a common font\n",
        "            except IOError:\n",
        "                try:\n",
        "                     font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\", font_size)\n",
        "                except IOError:\n",
        "                    print(\"Font file not found, using default PIL font.\")\n",
        "                    font = ImageFont.load_default()\n",
        "\n",
        "            for box_info in result.get('boxes', []):\n",
        "                xyxy = box_info['xyxy']\n",
        "                class_name = box_info['class_name']\n",
        "                confidence = box_info['confidence']\n",
        "                label = f\"{class_name}: {confidence:.2f}\"\n",
        "\n",
        "                # Draw bounding box\n",
        "                draw.rectangle(xyxy, outline=\"red\", width=2)\n",
        "\n",
        "                # Draw label background and text\n",
        "                text_width, text_height = draw.textbbox((0, 0), label, font=font)[2:]\n",
        "\n",
        "                # Adjust position to stay within image bounds\n",
        "                text_x = xyxy[0]\n",
        "                text_y = xyxy[1] - text_height - 5 # Position above the box\n",
        "\n",
        "                if text_y < 0: # If text is above top edge, put it below\n",
        "                    text_y = xyxy[1] + 5\n",
        "                    if text_y + text_height > annotated_image.height: # If still outside, adjust x\n",
        "                         text_x = xyxy[0] + (xyxy[2] - xyxy[0]) / 2 - text_width / 2\n",
        "                         text_y = xyxy[1] + 5 # Still below the box\n",
        "\n",
        "                # Ensure text_x is also within bounds\n",
        "                if text_x < 0: text_x = 0\n",
        "                if text_x + text_width > annotated_image.width: text_x = annotated_image.width - text_width\n",
        "\n",
        "\n",
        "                draw.rectangle([text_x, text_y, text_x + text_width, text_y + text_height], fill=\"red\")\n",
        "                draw.text((text_x, text_y), label, fill=\"white\", font=font)\n",
        "\n",
        "\n",
        "            output_images.append(annotated_image)\n",
        "        else:\n",
        "            output_images.append(None) # Append None if processing failed\n",
        "\n",
        "        # Format tags for display\n",
        "        tags = result.get('tags', [])\n",
        "        if tags:\n",
        "            output_tags.append(f\"Изображение {i+1}: {', '.join(tags)}\")\n",
        "        elif result.get('error'):\n",
        "             output_tags.append(f\"Изображение {i+1}: Ошибка обработки - {result['error']}\")\n",
        "        else:\n",
        "            output_tags.append(f\"Изображение {i+1}: Повреждения не обнаружены\")\n",
        "\n",
        "\n",
        "    # Combine all tag strings\n",
        "    all_tags_string = \"\\\\n\".join(output_tags)\n",
        "\n",
        "    # Gradio expects a fixed number of outputs.\n",
        "    # If we expect up to 5 images, return a list of 5 images and the tags string.\n",
        "    # Pad the output_images list with None if fewer than 5 images were uploaded.\n",
        "    while len(output_images) < 5:\n",
        "        output_images.append(None)\n",
        "\n",
        "\n",
        "    return output_images[0], output_images[1], output_images[2], output_images[3], output_images[4], all_tags_string\n",
        "\n",
        "\n",
        "\n",
        "# Define the Gradio interface\n",
        "# Use multiple Image components for output, up to a reasonable number (e.g., 5)\n",
        "interface = gr.Interface(\n",
        "    fn=process_for_gradio,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 1\", optional=True),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 2\", optional=True),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 3\", optional=True),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 4\", optional=True),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 5\", optional=True),\n",
        "        gr.Textbox(label=\"Марка автомобиля\"),\n",
        "        gr.Textbox(label=\"Госномер\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Результат обработки 1\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 2\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 3\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 4\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 5\", interactive=False),\n",
        "        gr.Textbox(label=\"Обнаруженные теги и информация\"),\n",
        "    ],\n",
        "    title=\"Приложение для определения повреждений автомобиля (Indrive Style)\",\n",
        "    description=\"Загрузите фотографии автомобиля, укажите марку и госномер для определения повреждений.\",\n",
        "    theme=\"default\" # Using default theme, custom styling would require CSS\n",
        ")\n",
        "\n",
        "# The interface can be launched using interface.launch()\n",
        "# In this notebook environment, we might just define it."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Image.__init__() got an unexpected keyword argument 'optional'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4057459634.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_for_gradio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     inputs=[\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pil\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Загрузите фото автомобиля 1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pil\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Загрузите фото автомобиля 2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pil\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Загрузите фото автомобиля 3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/component_meta.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Image.__init__() got an unexpected keyword argument 'optional'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5228f844"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because `gr.Image` does not accept the `optional` keyword argument. I need to remove the `optional=True` from the `gr.Image` inputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPP8VyHOnuqX"
      },
      "source": [
        "import gradio as gr\n",
        "import io\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Assume process_car_images function is defined in the previous step\n",
        "\n",
        "def process_for_gradio(image1, image2, image3, image4, image5, car_make, license_plate):\n",
        "    \"\"\"\n",
        "    Wrapper function to process images for Gradio output.\n",
        "    Takes up to 5 Gradio Image components and returns a list of annotated images\n",
        "    and a formatted string of tags.\n",
        "    \"\"\"\n",
        "    # Collect non-None images and ensure they are PIL Image objects if possible\n",
        "    image_list = []\n",
        "    for img in [image1, image2, image3, image4, image5]:\n",
        "        if img is not None:\n",
        "            if isinstance(img, Image.Image):\n",
        "                image_list.append(img)\n",
        "            # Add other type checks if Gradio might pass other formats (e.g., numpy arrays, file paths)\n",
        "            # For Gradio's Image component with type=\"pil\", it should ideally pass PIL Image.\n",
        "            else:\n",
        "                 print(f\"Warning: Unexpected image format received by Gradio wrapper: {type(img)}\")\n",
        "                 # Attempt to convert if it's a path or bytes, though type=\"pil\" should handle this\n",
        "                 try:\n",
        "                     if isinstance(img, str): # Assuming it might be a file path\n",
        "                          image_list.append(Image.open(img).convert(\"RGB\"))\n",
        "                     elif isinstance(img, bytes): # Assuming it might be bytes\n",
        "                          image_list.append(Image.open(io.BytesIO(img)).convert(\"RGB\"))\n",
        "                     # Add other conversions if necessary\n",
        "                     else:\n",
        "                          print(f\"Error: Cannot process image of type {type(img)}\")\n",
        "                          # Optionally add an error entry to results_data here if conversion fails\n",
        "                 except Exception as e:\n",
        "                      print(f\"Error converting image type: {e}\")\n",
        "                      # Optionally add an error entry to results_data here if conversion fails\n",
        "\n",
        "\n",
        "    if not image_list:\n",
        "        # Return placeholders for outputs if no images are uploaded\n",
        "        # Also return empty string for overall tags\n",
        "        return None, None, None, None, None, \"\", \"Пожалуйста, загрузите хотя бы одно изображение.\"\n",
        "\n",
        "    # Process images using the core logic\n",
        "    # The process_car_images function is expected to handle a list of PIL Image objects\n",
        "    try:\n",
        "        processing_results = process_car_images(image_list, car_make, license_plate)\n",
        "    except NameError:\n",
        "        # Handle case where process_car_images is not defined (e.g., running this cell alone)\n",
        "        return None, None, None, None, None, \"\", \"Ошибка: Функция обработки изображений не определена.\"\n",
        "    except Exception as e:\n",
        "         return None, None, None, None, None, \"\", f\"Общая ошибка обработки: {e}\"\n",
        "\n",
        "\n",
        "    output_images = []\n",
        "    output_individual_tags = []\n",
        "    overall_tags_set = set() # Set to store unique overall tags\n",
        "\n",
        "    # Prepare output for Gradio\n",
        "    for i, result in enumerate(processing_results):\n",
        "        # Check if processing was successful for this image\n",
        "        if result.get('original_image') and not result.get('error'):\n",
        "            # Annotate the image with bounding boxes and class names\n",
        "            annotated_image = result['original_image'].copy()\n",
        "            draw = ImageDraw.Draw(annotated_image)\n",
        "            font = None # Use default font\n",
        "\n",
        "            # Try to load a font\n",
        "            try:\n",
        "                font_size = max(10, annotated_image.width // 50) # Dynamic font size\n",
        "                # Use fonts commonly available in Colab\n",
        "                font_paths = [\"DejaVuSans-Bold.ttf\", \"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\"]\n",
        "                for font_path in font_paths:\n",
        "                    try:\n",
        "                        font = ImageFont.truetype(font_path, font_size)\n",
        "                        break # Found a font, exit loop\n",
        "                    except IOError:\n",
        "                        continue # Try next font\n",
        "\n",
        "                if font is None:\n",
        "                     print(\"Warning: Font file not found, using default PIL font.\")\n",
        "                     font = ImageFont.load_default()\n",
        "\n",
        "\n",
        "            except Exception as font_e:\n",
        "                print(f\"Error loading font: {font_e}\")\n",
        "                font = ImageFont.load_default() # Fallback to default font\n",
        "\n",
        "\n",
        "            for box_info in result.get('boxes', []):\n",
        "                xyxy = box_info['xyxy']\n",
        "                class_name = box_info['class_name']\n",
        "                confidence = box_info['confidence']\n",
        "                label = f\"{class_name}: {confidence:.2f}\"\n",
        "\n",
        "                # Draw bounding box\n",
        "                draw.rectangle(xyxy, outline=\"red\", width=2)\n",
        "\n",
        "                # Draw label background and text\n",
        "                try:\n",
        "                    text_width, text_height = draw.textbbox((0, 0), label, font=font)[2:]\n",
        "                except AttributeError: # Handle older PIL versions without textbbox\n",
        "                     text_width, text_height = draw.textsize(label, font=font)\n",
        "\n",
        "\n",
        "                # Adjust position to stay within image bounds\n",
        "                text_x = xyxy[0]\n",
        "                text_y = xyxy[1] - text_height - 5 # Position above the box\n",
        "\n",
        "                if text_y < 0: # If text is above top edge, put it below\n",
        "                    text_y = xyxy[1] + 5\n",
        "                    # If still outside, adjust x to center if possible\n",
        "                    if text_y + text_height > annotated_image.height:\n",
        "                         text_x = xyxy[0] + (xyxy[2] - xyxy[0]) / 2 - text_width / 2\n",
        "                         text_y = xyxy[1] + 5 # Still below the box\n",
        "\n",
        "                # Ensure text_x is also within bounds\n",
        "                if text_x < 0: text_x = 0\n",
        "                if text_x + text_width > annotated_image.width: text_x = annotated_image.width - text_width\n",
        "\n",
        "                try:\n",
        "                    draw.rectangle([text_x, text_y, text_x + text_width, text_y + text_height], fill=\"red\")\n",
        "                    draw.text((text_x, text_y), label, fill=\"white\", font=font)\n",
        "                except Exception as draw_e:\n",
        "                    print(f\"Error drawing on image: {draw_e}\")\n",
        "\n",
        "\n",
        "            output_images.append(annotated_image)\n",
        "\n",
        "            # Add individual image tags to the list\n",
        "            tags = result.get('tags', [])\n",
        "            if tags:\n",
        "                output_individual_tags.append(f\"Изображение {i+1}: {', '.join(tags)}\")\n",
        "                # Add tags to the overall set (excluding error tags for overall summary)\n",
        "                overall_tags_set.update([t for t in tags if not t.startswith('Ошибка')])\n",
        "            else:\n",
        "                output_individual_tags.append(f\"Изображение {i+1}: Повреждения не обнаружены\")\n",
        "\n",
        "        else:\n",
        "            # If processing failed or no image was returned, append None\n",
        "            output_images.append(None)\n",
        "            # Report error for this specific image\n",
        "            error_msg = result.get('error', 'Неизвестная ошибка')\n",
        "            output_individual_tags.append(f\"Изображение {i+1}: Ошибка обработки - {error_msg}\")\n",
        "            # Add general error tag to overall tags if applicable\n",
        "            overall_tags_set.add(\"Общая ошибка обработки\")\n",
        "\n",
        "\n",
        "    # Filter overall tags to include only \"битый\" and \"грязный\" and format for display\n",
        "    filtered_overall_tags = []\n",
        "    if 'битый' in overall_tags_set:\n",
        "        filtered_overall_tags.append('БИТЫЙ')\n",
        "    if 'грязный' in overall_tags_set:\n",
        "        filtered_overall_tags.append('ГРЯЗНЫЙ')\n",
        "    # Add other specific tags if needed, e.g., for errors\n",
        "    if 'Общая ошибка обработки' in overall_tags_set:\n",
        "         filtered_overall_tags.append('Общая ошибка обработки') # Include general error tag\n",
        "\n",
        "\n",
        "    overall_tags_string = \"Общие теги повреждений: \" + (\", \".join(filtered_overall_tags) if filtered_overall_tags else \"Нет обнаружено\")\n",
        "    individual_tags_string = \"\\\\n\".join(output_individual_tags)\n",
        "\n",
        "    # Combine overall and individual tags in the final output string\n",
        "    final_tags_output = f\"{overall_tags_string}\\\\n\\\\nРезультаты по изображениям:\\\\n{individual_tags_string}\"\n",
        "\n",
        "\n",
        "    # Gradio expects a fixed number of outputs.\n",
        "    # If we expect up to 5 images, return a list of 5 images and the tags string.\n",
        "    # Pad the output_images list with None if fewer than 5 images were processed successfully.\n",
        "    while len(output_images) < 5:\n",
        "        output_images.append(None)\n",
        "\n",
        "\n",
        "    # Return the 5 images and the combined tag string\n",
        "    return output_images[0], output_images[1], output_images[2], output_images[3], output_images[4], final_tags_output\n",
        "\n",
        "\n",
        "# Define the Gradio interface\n",
        "# Use multiple Image components for output, up to a reasonable number (e.g., 5)\n",
        "# The custom CSS is defined in the previous step and will be applied when the interface is launched.\n",
        "interface = gr.Interface(\n",
        "    fn=process_for_gradio,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 1\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 2\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 3\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 4\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 5\"),\n",
        "        gr.Textbox(label=\"Марка автомобиля\"),\n",
        "        gr.Textbox(label=\"Госномер\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Результат обработки 1\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 2\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 3\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 4\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 5\", interactive=False),\n",
        "        gr.Textbox(label=\"Обнаруженные теги и информация\"),\n",
        "    ],\n",
        "    title=\"Приложение для определения повреждений автомобиля (Indrive Style)\",\n",
        "    description=\"Загрузите фотографии автомобиля, укажите марку и госномер для определения повреждений.\",\n",
        "    css=\"\"\"\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';\n",
        "    background-color: #f0f2f5; /* Light grey background */\n",
        "    color: #333; /* Dark grey text */\n",
        "}\n",
        "h1, h2, h3, h4, h5, h6 {\n",
        "    color: #007bff; /* Indrive blue-ish color for headings */\n",
        "}\n",
        ".gradio-container {\n",
        "    box-shadow: 0 4px 8px rgba(0,0,0,0.1); /* Subtle shadow */\n",
        "    border-radius: 8px;\n",
        "    padding: 20px;\n",
        "    background-color: #ffffff; /* White background for the container */\n",
        "}\n",
        "/* Style for text inputs */\n",
        ".gr-textbox textarea {\n",
        "    border-color: #ced4da;\n",
        "    border-radius: 4px;\n",
        "    padding: 10px;\n",
        "}\n",
        "/* Style for buttons */\n",
        ".gr-button {\n",
        "    background-color: #007bff; /* Indrive blue-ish color */\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 4px;\n",
        "    padding: 10px 20px;\n",
        "    font-size: 16px;\n",
        "    cursor: pointer;\n",
        "    transition: background-color 0.3s ease;\n",
        "}\n",
        ".gr-button:hover {\n",
        "    background-color: #0056b3; /* Darker blue on hover */\n",
        "}\n",
        "/* Style for file upload area */\n",
        ".gr-upload-text {\n",
        "    color: #007bff; /* Indrive blue-ish color */\n",
        "}\n",
        "/* Style for labels */\n",
        ".gr-label {\n",
        "    font-weight: bold;\n",
        "    color: #555;\n",
        "}\n",
        "/* Style for output text */\n",
        ".gr-text output {\n",
        "    white-space: pre-wrap; /* Preserve line breaks in output */\n",
        "}\n",
        "\"\"\", # Apply custom CSS directly\n",
        "    # theme=gr.themes.Soft() # Example of applying a built-in theme\n",
        ")\n",
        "\n",
        "# The interface can be launched using interface.launch()\n",
        "# The launch command is in a separate cell."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73359cc8"
      },
      "source": [
        "## Интеграция с моделями\n",
        "\n",
        "### Subtask:\n",
        "Подключите функцию обработки изображений к интерфейсу Gradio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eea8c77b"
      },
      "source": [
        "## Запуск приложения gradio\n",
        "\n",
        "### Subtask:\n",
        "Запустите веб-приложение Gradio, возможно, с использованием `share=True` для доступа через публичную ссылку в Colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c14792ec"
      },
      "source": [
        "**Reasoning**:\n",
        "Call the launch method on the Gradio interface object to start the web server and generate a public shareable URL.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "d6a9551c",
        "outputId": "96444053-3e8e-41d6-a52f-90fdfa1943c3"
      },
      "source": [
        "interface.launch(share=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'interface' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3541891527.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'interface' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b722d51"
      },
      "source": [
        "# Приложение для определения повреждений автомобиля (Indrive Style)\n",
        "\n",
        "Это веб-приложение, созданное с использованием Gradio и YOLO моделей, для загрузки фотографий автомобилей, определения типов повреждений (таких как \"битый\", \"царапина\", \"грязный\") и отображения результатов.\n",
        "\n",
        "## Описание\n",
        "\n",
        "Приложение позволяет пользователям загружать несколько фотографий автомобиля и предоставлять основную информацию (марка, госномер). Затем оно использует предобученные YOLO модели для анализа каждого изображения на наличие повреждений. Результаты обработки включают отображение исходного изображения с нанесенными ограничивающими рамками и метками обнаруженных повреждений, а также сводный список обнаруженных тегов повреждений для всего автомобиля.\n",
        "\n",
        "Интерфейс приложения стилизован для приближения к дизайну в стиле Indrive.\n",
        "\n",
        "## Требования\n",
        "\n",
        "*   Python 3.7+\n",
        "*   `gradio`\n",
        "*   `ultralytics`\n",
        "*   `Pillow`\n",
        "*   `torch` и `torchvision` (для работы `ultralytics`)\n",
        "*   `npx localtunnel` (для запуска в Google Colab с публичным доступом)\n",
        "\n",
        "## Установка\n",
        "\n",
        "1.  **Клонируйте репозиторий (если применимо) или загрузите файлы проекта.**\n",
        "2.  **Установите необходимые библиотеки Python:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "027756a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "5f837d1f-e603-4fd7-c3af-88c779cdbaf3"
      },
      "source": [
        "    interface.launch(share=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'interface' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3347225755.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'interface' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "852cff66"
      },
      "source": [
        "    !curl ipecho.net/plain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db175d43"
      },
      "source": [
        "    python app.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ed84e06"
      },
      "source": [
        "## Стилизация (опционально)\n",
        "\n",
        "### Subtask:\n",
        "Попробуйте применить базовую стилизацию, чтобы приблизиться к дизайну в стиле Indrive, насколько это возможно средствами Gradio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d8e7fef"
      },
      "source": [
        "**Reasoning**:\n",
        "I will explore the available Gradio themes and potentially add custom CSS to the interface to attempt to match the Indrive style as much as possible within the constraints of Gradio's styling capabilities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b13c463"
      },
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Assume process_car_images function is defined in a previous step\n",
        "\n",
        "def process_for_gradio(image1, image2, image3, image4, image5, car_make, license_plate):\n",
        "    \"\"\"\n",
        "    Wrapper function to process images for Gradio output.\n",
        "    Takes up to 5 Gradio Image components and returns a list of annotated images\n",
        "    and a formatted string of tags.\n",
        "    \"\"\"\n",
        "    image_list = [img for img in [image1, image2, image3, image4, image5] if img is not None]\n",
        "\n",
        "    if not image_list:\n",
        "        # Return placeholders for outputs if no images are uploaded\n",
        "        return None, None, None, None, None, \"Пожалуйста, загрузите хотя бы одно изображение.\"\n",
        "\n",
        "    # Process images using the core logic (assuming process_car_images is available)\n",
        "    # Note: In a real app, you might want to handle model loading more efficiently\n",
        "    # (e.g., load once outside this function).\n",
        "    try:\n",
        "        processing_results = process_car_images(image_list, car_make, license_plate)\n",
        "    except NameError:\n",
        "        # Handle case where process_car_images is not defined (e.g., running this cell alone)\n",
        "        return None, None, None, None, None, \"Ошибка: Функция обработки изображений не определена.\"\n",
        "    except Exception as e:\n",
        "         return None, None, None, None, None, f\"Ошибка обработки: {e}\"\n",
        "\n",
        "\n",
        "    output_images = []\n",
        "    output_tags = []\n",
        "\n",
        "    # Prepare output for Gradio\n",
        "    for i, result in enumerate(processing_results):\n",
        "        if result.get('original_image'):\n",
        "            # Annotate the image with bounding boxes and class names\n",
        "            annotated_image = result['original_image'].copy()\n",
        "            draw = ImageDraw.Draw(annotated_image)\n",
        "            font = None # Use default font\n",
        "\n",
        "            # Try to load a font\n",
        "            try:\n",
        "                font_size = max(10, annotated_image.width // 50) # Dynamic font size\n",
        "                font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", font_size) # Use a common font\n",
        "            except IOError:\n",
        "                try:\n",
        "                     font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\", font_size)\n",
        "                except IOError:\n",
        "                    print(\"Font file not found, using default PIL font.\")\n",
        "                    font = ImageFont.load_default()\n",
        "\n",
        "            for box_info in result.get('boxes', []):\n",
        "                xyxy = box_info['xyxy']\n",
        "                class_name = box_info['class_name']\n",
        "                confidence = box_info['confidence']\n",
        "                label = f\"{class_name}: {confidence:.2f}\"\n",
        "\n",
        "                # Draw bounding box\n",
        "                draw.rectangle(xyxy, outline=\"red\", width=2)\n",
        "\n",
        "                # Draw label background and text\n",
        "                try:\n",
        "                    text_width, text_height = draw.textbbox((0, 0), label, font=font)[2:]\n",
        "                except AttributeError: # Handle older PIL versions without textbbox\n",
        "                     text_width, text_height = draw.textsize(label, font=font)\n",
        "\n",
        "\n",
        "                # Adjust position to stay within image bounds\n",
        "                text_x = xyxy[0]\n",
        "                text_y = xyxy[1] - text_height - 5 # Position above the box\n",
        "\n",
        "                if text_y < 0: # If text is above top edge, put it below\n",
        "                    text_y = xyxy[1] + 5\n",
        "                    # If still outside, adjust x to center if possible\n",
        "                    if text_y + text_height > annotated_image.height:\n",
        "                         text_x = xyxy[0] + (xyxy[2] - xyxy[0]) / 2 - text_width / 2\n",
        "                         text_y = xyxy[1] + 5 # Still below the box\n",
        "\n",
        "                # Ensure text_x is also within bounds\n",
        "                if text_x < 0: text_x = 0\n",
        "                if text_x + text_width > annotated_image.width: text_x = annotated_image.width - text_width\n",
        "\n",
        "\n",
        "                draw.rectangle([text_x, text_y, text_x + text_width, text_y + text_height], fill=\"red\")\n",
        "                draw.text((text_x, text_y), label, fill=\"white\", font=font)\n",
        "\n",
        "\n",
        "            output_images.append(annotated_image)\n",
        "        else:\n",
        "            output_images.append(None) # Append None if processing failed\n",
        "\n",
        "        # Format tags for display\n",
        "        tags = result.get('tags', [])\n",
        "        if tags:\n",
        "            output_tags.append(f\"Изображение {i+1}: {', '.join(tags)}\")\n",
        "        elif result.get('error'):\n",
        "             output_tags.append(f\"Изображение {i+1}: Ошибка обработки - {result['error']}\")\n",
        "        else:\n",
        "            output_tags.append(f\"Изображение {i+1}: Повреждения не обнаружены\")\n",
        "\n",
        "\n",
        "    # Combine all tag strings\n",
        "    all_tags_string = \"\\\\n\".join(output_tags)\n",
        "\n",
        "    # Gradio expects a fixed number of outputs.\n",
        "    # If we expect up to 5 images, return a list of 5 images and the tags string.\n",
        "    # Pad the output_images list with None if fewer than 5 images were uploaded.\n",
        "    while len(output_images) < 5:\n",
        "        output_images.append(None)\n",
        "\n",
        "\n",
        "    return output_images[0], output_images[1], output_images[2], output_images[3], output_images[4], all_tags_string\n",
        "\n",
        "\n",
        "# Define custom CSS to attempt Indrive-like styling\n",
        "# This is a basic attempt; a full Indrive style would be complex\n",
        "custom_css = \"\"\"\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';\n",
        "    background-color: #f0f2f5; /* Light grey background */\n",
        "    color: #333; /* Dark grey text */\n",
        "}\n",
        "h1, h2, h3, h4, h5, h6 {\n",
        "    color: #007bff; /* Indrive blue-ish color for headings */\n",
        "}\n",
        ".gradio-container {\n",
        "    box-shadow: 0 4px 8px rgba(0,0,0,0.1); /* Subtle shadow */\n",
        "    border-radius: 8px;\n",
        "    padding: 20px;\n",
        "    background-color: #ffffff; /* White background for the container */\n",
        "}\n",
        "/* Style for text inputs */\n",
        ".gr-textbox textarea {\n",
        "    border-color: #ced4da;\n",
        "    border-radius: 4px;\n",
        "    padding: 10px;\n",
        "}\n",
        "/* Style for buttons */\n",
        ".gr-button {\n",
        "    background-color: #007bff; /* Indrive blue-ish color */\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 4px;\n",
        "    padding: 10px 20px;\n",
        "    font-size: 16px;\n",
        "    cursor: pointer;\n",
        "    transition: background-color 0.3s ease;\n",
        "}\n",
        ".gr-button:hover {\n",
        "    background-color: #0056b3; /* Darker blue on hover */\n",
        "}\n",
        "/* Style for file upload area */\n",
        ".gr-upload-text {\n",
        "    color: #007bff; /* Indrive blue-ish color */\n",
        "}\n",
        "/* Style for labels */\n",
        ".gr-label {\n",
        "    font-weight: bold;\n",
        "    color: #555;\n",
        "}\n",
        "/* Style for output text */\n",
        ".gr-text output {\n",
        "    white-space: pre-wrap; /* Preserve line breaks in output */\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Define the Gradio interface with custom CSS and potentially a different theme\n",
        "interface = gr.Interface(\n",
        "    fn=process_for_gradio,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 1\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 2\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 3\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 4\"),\n",
        "        gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля 5\"),\n",
        "        gr.Textbox(label=\"Марка автомобиля\"),\n",
        "        gr.Textbox(label=\"Госномер\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Результат обработки 1\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 2\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 3\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 4\", interactive=False),\n",
        "        gr.Image(label=\"Результат обработки 5\", interactive=False),\n",
        "        gr.Textbox(label=\"Обнаруженные теги и информация\"),\n",
        "    ],\n",
        "    title=\"Приложение для определения повреждений автомобиля (Indrive Style)\",\n",
        "    description=\"Загрузите фотографии автомобиля, укажите марку и госномер для определения повреждений.\",\n",
        "    css=custom_css, # Apply custom CSS\n",
        "    # Explore different built-in themes if needed:\n",
        "    # theme=gr.themes.Soft()\n",
        "    # theme=gr.themes.Glass()\n",
        "    # theme=gr.themes.Monochrome()\n",
        "    # theme=\"default\" # Keep default or try others\n",
        ")\n",
        "\n",
        "# The interface can be launched using interface.launch()\n",
        "# In this notebook environment, we might just define it here.\n",
        "# The launch command was in the previous step."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0723b64a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The required libraries, including `gradio` and `Pillow`, were already installed in the environment. The presence of `ultralytics` and `torch` was inferred from the context of the task.\n",
        "*   A Python function `process_car_images` was successfully defined to handle image loading, multi-model YOLO object detection, extraction of detected class names, and determination of damage-related tags (`битый`, `царапина`). It also includes error handling for individual image processing.\n",
        "*   A wrapper function `process_for_gradio` was created to adapt the core processing logic for the Gradio interface, handling multiple image inputs, annotating images with bounding boxes and labels using PIL, and formatting the output tags.\n",
        "*   The Gradio web interface was successfully defined using `gr.Interface`, including components for uploading up to five images (`gr.Image`), inputting car make and license plate (`gr.Textbox`), and displaying processed images (`gr.Image`) and detected tags (`gr.Textbox`).\n",
        "*   The core processing function (`process_for_gradio`) was successfully linked to the Gradio interface function call (`fn=process_for_gradio`).\n",
        "*   The Gradio application was successfully launched, generating a public shareable URL for external access.\n",
        "*   Basic custom CSS was applied to the Gradio interface to attempt a visual approximation of the Indrive style, modifying colors, fonts, and component appearance.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Further refinement of the styling with more detailed CSS could bring the interface closer to the target Indrive design.\n",
        "*   Implementing more robust error handling and user feedback within the Gradio interface could improve usability.\n"
      ]
    }
  ]
}